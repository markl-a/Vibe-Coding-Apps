"""
Enhanced RAG Chatbot Example
å±•ç¤ºèªç¾©åˆ†å¡Šã€æ··åˆæœç´¢ã€é‡æ’åºç­‰é€²éšåŠŸèƒ½
"""

from rag_bot import RAGChatbot
from pathlib import Path
import json


def main():
    print("=" * 70)
    print("å¢å¼·ç‰ˆ RAG èŠå¤©æ©Ÿå™¨äººç¤ºä¾‹")
    print("=" * 70)
    print()

    # åˆå§‹åŒ–æ©Ÿå™¨äººï¼ˆå•Ÿç”¨æ‰€æœ‰å¢å¼·åŠŸèƒ½ï¼‰
    print("åˆå§‹åŒ–æ©Ÿå™¨äºº...")
    bot = RAGChatbot(
        vector_db_path="./vector_db_enhanced",
        model="gpt-4o-mini",
        chunk_size=800,
        chunk_overlap=100,
        chunk_strategy="semantic",  # ä½¿ç”¨èªç¾©åˆ†å¡Š
        enable_reranking=True,  # å•Ÿç”¨AIé‡æ’åº
        enable_hybrid_search=True  # å•Ÿç”¨æ··åˆæœç´¢
    )
    print("âœ“ æ©Ÿå™¨äººåˆå§‹åŒ–å®Œæˆ")
    print(f"  åˆ†å¡Šç­–ç•¥: semantic")
    print(f"  æ··åˆæœç´¢: å•Ÿç”¨")
    print(f"  AIé‡æ’åº: å•Ÿç”¨")
    print()

    # æª¢æŸ¥ç¾æœ‰æ–‡æª”
    stats = bot.get_stats()
    print(f"ğŸ“Š ç•¶å‰ç‹€æ…‹:")
    print(f"  æ–‡æª”æ•¸: {stats['total_documents']}")
    print(f"  ç‰‡æ®µæ•¸: {stats['total_chunks']}")
    if stats['sources']:
        print(f"  ä¾†æº: {', '.join(stats['sources'][:3])}")
    print()

    # å¦‚æœæ²’æœ‰æ–‡æª”ï¼Œæ·»åŠ ç¤ºä¾‹æ–‡æª”
    if stats['total_chunks'] == 0:
        print("=" * 70)
        print("ğŸ“„ æ·»åŠ ç¤ºä¾‹æ–‡æª”")
        print("=" * 70)

        documents_dir = Path("documents")
        if documents_dir.exists():
            docs = list(documents_dir.glob("*"))
            for doc_path in docs[:3]:  # åªæ·»åŠ å‰3å€‹æ–‡æª”
                print(f"\nè™•ç†: {doc_path.name}")
                try:
                    bot.add_document(
                        str(doc_path),
                        metadata={"filename": doc_path.name}
                    )
                except Exception as e:
                    print(f"éŒ¯èª¤: {e}")

        # æ›´æ–°çµ±è¨ˆ
        stats = bot.get_stats()
        print(f"\næ›´æ–°å¾Œçš„çµ±è¨ˆ:")
        print(f"  æ–‡æª”æ•¸: {stats['total_documents']}")
        print(f"  ç‰‡æ®µæ•¸: {stats['total_chunks']}")

    # æ¸¬è©¦æŸ¥è©¢
    print("\n" + "=" * 70)
    print("ğŸ” æ¸¬è©¦æŸ¥è©¢")
    print("=" * 70)

    test_queries = [
        "ç”¢å“ä¿å›ºæ”¿ç­–æ˜¯ä»€éº¼ï¼Ÿ",
        "å¦‚ä½•å®‰è£å’Œè¨­ç½®ç”¢å“ï¼Ÿ",
        "å…¬å¸çš„é€€è²¨æµç¨‹å¦‚ä½•é€²è¡Œï¼Ÿ"
    ]

    for i, query in enumerate(test_queries, 1):
        print(f"\n{'-' * 70}")
        print(f"æŸ¥è©¢ {i}: {query}")
        print(f"{'-' * 70}")

        # åŸ·è¡ŒæŸ¥è©¢
        result = bot.query(
            question=query,
            top_k=3,
            include_sources=True
        )

        # é¡¯ç¤ºçµæœ
        print(f"\nâœ¨ å›ç­”:")
        print(result['answer'])
        print(f"\nğŸ“ˆ ä¿¡å¿ƒåº¦: {result['confidence']:.2%}")

        if result.get('sources'):
            print(f"\nğŸ“š ä¾†æºæ–‡æª”:")
            for j, source in enumerate(result['sources'], 1):
                print(f"  {j}. {source['source']}")
                print(f"     ç›¸é—œåº¦: {source['relevance_score']:.2%}")

    # æ¸¬è©¦ä¸åŒæœç´¢ç­–ç•¥
    print("\n" + "=" * 70)
    print("ğŸ”¬ æ¯”è¼ƒæœç´¢ç­–ç•¥")
    print("=" * 70)

    test_query = "ä¿å›ºæœŸé™"

    # 1. åƒ…å‘é‡æœç´¢
    print(f"\næŸ¥è©¢: {test_query}")
    print(f"\n1ï¸âƒ£  å‘é‡æœç´¢ (Vector Search):")
    bot.enable_hybrid_search = False
    bot.enable_reranking = False
    results = bot.similarity_search(test_query, k=3)
    for i, (chunk, meta, score) in enumerate(results, 1):
        print(f"  {i}. [{meta.get('source', 'Unknown')}] (åˆ†æ•¸: {score:.3f})")
        print(f"     {chunk[:100]}...")

    # 2. æ··åˆæœç´¢
    print(f"\n2ï¸âƒ£  æ··åˆæœç´¢ (Hybrid Search):")
    bot.enable_hybrid_search = True
    bot.enable_reranking = False
    results = bot.similarity_search(test_query, k=3)
    for i, (chunk, meta, score) in enumerate(results, 1):
        print(f"  {i}. [{meta.get('source', 'Unknown')}] (åˆ†æ•¸: {score:.3f})")
        print(f"     {chunk[:100]}...")

    # 3. æ··åˆæœç´¢ + é‡æ’åº
    print(f"\n3ï¸âƒ£  æ··åˆæœç´¢ + AIé‡æ’åº:")
    bot.enable_hybrid_search = True
    bot.enable_reranking = True
    results = bot.similarity_search(test_query, k=3)
    for i, (chunk, meta, score) in enumerate(results, 1):
        print(f"  {i}. [{meta.get('source', 'Unknown')}] (åˆ†æ•¸: {score:.3f})")
        print(f"     {chunk[:100]}...")

    # æ¸¬è©¦åˆ†å¡Šç­–ç•¥
    print("\n" + "=" * 70)
    print("ğŸ“ åˆ†å¡Šç­–ç•¥æ¯”è¼ƒ")
    print("=" * 70)

    sample_text = """
é€™æ˜¯ç¬¬ä¸€æ®µæ–‡å­—ã€‚å®ƒè¨è«–ç”¢å“çš„åŸºæœ¬è³‡è¨Šã€‚

é€™æ˜¯ç¬¬äºŒæ®µæ–‡å­—ã€‚å®ƒè¨è«–ç”¢å“çš„æŠ€è¡“è¦æ ¼ã€‚
è¦æ ¼åŒ…æ‹¬å°ºå¯¸ã€é‡é‡å’Œæè³ªã€‚

é€™æ˜¯ç¬¬ä¸‰æ®µæ–‡å­—ã€‚å®ƒè¨è«–ç”¢å“çš„ä½¿ç”¨æ–¹æ³•ã€‚
ä½¿ç”¨æ–¹æ³•éå¸¸ç°¡å–®ï¼Œåªéœ€æŒ‰ç…§èªªæ˜æ“ä½œå³å¯ã€‚
""" * 3  # é‡è¤‡3æ¬¡ä»¥ç”¢ç”Ÿæ›´é•·çš„æ–‡æœ¬

    print("\nå›ºå®šå¤§å°åˆ†å¡Š:")
    fixed_chunks = bot._fixed_chunk(sample_text)
    print(f"  ç‰‡æ®µæ•¸: {len(fixed_chunks)}")
    for i, chunk in enumerate(fixed_chunks[:2], 1):
        print(f"  ç‰‡æ®µ{i}: {len(chunk)} å­—ç¬¦")

    print("\nèªç¾©åˆ†å¡Š:")
    semantic_chunks = bot._semantic_chunk(sample_text)
    print(f"  ç‰‡æ®µæ•¸: {len(semantic_chunks)}")
    for i, chunk in enumerate(semantic_chunks[:2], 1):
        print(f"  ç‰‡æ®µ{i}: {len(chunk)} å­—ç¬¦")

    # æ€§èƒ½å»ºè­°
    print("\n" + "=" * 70)
    print("ğŸ’¡ å„ªåŒ–å»ºè­°")
    print("=" * 70)
    print("""
1. æ–‡æª”è³ªé‡ï¼š
   - ç¢ºä¿æ–‡æª”çµæ§‹æ¸…æ™°ï¼Œæ®µè½åˆ†æ˜
   - ä½¿ç”¨æ¨™é¡Œå’Œå­æ¨™é¡Œçµ„ç¹”å…§å®¹
   - é¿å…éé•·çš„æ®µè½

2. åˆ†å¡Šç­–ç•¥ï¼š
   - æŠ€è¡“æ–‡æª”ï¼šä½¿ç”¨èªç¾©åˆ†å¡Š
   - å°è©±æ–‡æœ¬ï¼šä½¿ç”¨å›ºå®šåˆ†å¡Š
   - æ··åˆå…§å®¹ï¼šæ¸¬è©¦å¾Œé¸æ“‡

3. æœç´¢ç­–ç•¥ï¼š
   - å°ˆæ¥­è¡“èªæœç´¢ï¼šæ··åˆæœç´¢æ•ˆæœæ›´å¥½
   - æ¦‚å¿µæ€§å•é¡Œï¼šå‘é‡æœç´¢å³å¯
   - é—œéµå­—æŸ¥è©¢ï¼šå•Ÿç”¨é‡æ’åº

4. æ€§èƒ½èª¿å„ªï¼š
   - èª¿æ•´chunk_size (500-1000)
   - èª¿æ•´top_k (3-5)
   - ç›£æ§APIä½¿ç”¨é‡
    """)

    print("\n" + "=" * 70)
    print("âœ… ç¤ºä¾‹é‹è¡Œå®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    main()
