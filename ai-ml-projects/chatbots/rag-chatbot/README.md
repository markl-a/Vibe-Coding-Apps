# RAG Chatbot - æª¢ç´¢å¢å¼·ç”ŸæˆèŠå¤©æ©Ÿå™¨äºº

ğŸ“š åŸºæ–¼ RAG (Retrieval-Augmented Generation) æŠ€è¡“çš„æ™ºèƒ½å•ç­”ç³»çµ±ï¼Œèƒ½å¤ åŸºæ–¼æ‚¨çš„æ–‡æª”è³‡æ–™åº«æä¾›ç²¾ç¢ºå›ç­”

## åŠŸèƒ½ç‰¹é»

- âœ… æ–‡æª”è‡ªå‹•ç´¢å¼•ï¼ˆPDFã€TXTã€Markdownã€DOCXï¼‰
- âœ… å‘é‡è³‡æ–™åº«å„²å­˜ï¼ˆFAISS/ChromaDBï¼‰
- âœ… èªç¾©æœå°‹
- âœ… ä¸Šä¸‹æ–‡æ„ŸçŸ¥å›ç­”
- âœ… ä¾†æºå¼•ç”¨è¿½è¹¤
- âœ… å¤šæ–‡æª”æ”¯æ´
- âœ… å¢é‡æ›´æ–°ç´¢å¼•
- âœ… è‡ªå®šç¾©åµŒå…¥æ¨¡å‹

## ä»€éº¼æ˜¯ RAGï¼Ÿ

RAG (Retrieval-Augmented Generation) æ˜¯ä¸€ç¨®çµåˆè³‡è¨Šæª¢ç´¢å’Œç”Ÿæˆå¼ AI çš„æŠ€è¡“ï¼š

1. **æª¢ç´¢ (Retrieval)**: å¾æ–‡æª”åº«ä¸­æ‰¾å‡ºç›¸é—œè³‡è¨Š
2. **å¢å¼· (Augmented)**: å°‡æª¢ç´¢åˆ°çš„è³‡è¨ŠåŠ å…¥æç¤ºè©
3. **ç”Ÿæˆ (Generation)**: åŸºæ–¼æª¢ç´¢è³‡è¨Šç”Ÿæˆæº–ç¢ºå›ç­”

## å¿«é€Ÿé–‹å§‹

### å®‰è£ä¾è³´

```bash
pip install -r requirements.txt
```

### é…ç½®

```bash
cp .env.example .env
# ç·¨è¼¯ .env è¨­å®š OpenAI API é‡‘é‘°
```

### 1. ç´¢å¼•æ–‡æª”

```bash
# å°‡æ–‡æª”æ”¾å…¥ documents/ ç›®éŒ„
cp your_docs.pdf documents/

# å»ºç«‹ç´¢å¼•
python build_index.py
```

### 2. åŸ·è¡ŒèŠå¤©æ©Ÿå™¨äºº

```bash
# å‘½ä»¤åˆ—æ¨¡å¼
python rag_bot.py

# Web UI æ¨¡å¼
streamlit run app.py
```

## ä½¿ç”¨ç¯„ä¾‹

```python
from rag_bot import RAGChatbot

# åˆå§‹åŒ– RAG èŠå¤©æ©Ÿå™¨äºº
bot = RAGChatbot(
    vector_db_path="./vector_db",
    model="gpt-3.5-turbo",
    chunk_size=500,
    chunk_overlap=50
)

# æ·»åŠ æ–‡æª”
bot.add_document("path/to/document.pdf")

# æå•
response = bot.query(
    "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ",
    top_k=3,  # æª¢ç´¢å‰ 3 å€‹æœ€ç›¸é—œç‰‡æ®µ
    include_sources=True
)

print(f"å›ç­”: {response['answer']}")
print(f"ä¾†æº: {response['sources']}")
```

## å°ˆæ¡ˆçµæ§‹

```
rag-chatbot/
â”œâ”€â”€ README.md              # å°ˆæ¡ˆèªªæ˜
â”œâ”€â”€ requirements.txt       # ä¾è³´å¥—ä»¶
â”œâ”€â”€ .env.example          # ç’°å¢ƒè®Šæ•¸ç¯„ä¾‹
â”œâ”€â”€ rag_bot.py            # RAG æ©Ÿå™¨äººæ ¸å¿ƒ
â”œâ”€â”€ app.py                # Streamlit UI
â”œâ”€â”€ build_index.py        # ç´¢å¼•å»ºç«‹å·¥å…·
â”œâ”€â”€ document_loader.py    # æ–‡æª”è¼‰å…¥å™¨
â”œâ”€â”€ vector_store.py       # å‘é‡è³‡æ–™åº«
â”œâ”€â”€ documents/            # å¾…ç´¢å¼•æ–‡æª”
â”‚   â””â”€â”€ sample.pdf
â””â”€â”€ vector_db/            # å‘é‡è³‡æ–™åº«å„²å­˜
```

## æ ¸å¿ƒæ¦‚å¿µ

### æ–‡æª”åˆ†å¡Š (Chunking)

å°‡é•·æ–‡æª”åˆ†å‰²æˆå°ç‰‡æ®µï¼Œä¾¿æ–¼æª¢ç´¢ï¼š

```python
bot = RAGChatbot(
    chunk_size=500,      # æ¯å¡Š 500 å­—å…ƒ
    chunk_overlap=50     # é‡ç–Š 50 å­—å…ƒé¿å…èªç¾©æ–·è£‚
)
```

### åµŒå…¥ (Embedding)

å°‡æ–‡æœ¬è½‰æ›ç‚ºå‘é‡è¡¨ç¤ºï¼š

```python
# ä½¿ç”¨ OpenAI åµŒå…¥æ¨¡å‹
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# æˆ–ä½¿ç”¨æœ¬åœ°æ¨¡å‹
from sentence_transformers import SentenceTransformer
embeddings = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
```

### å‘é‡æœå°‹

åŸºæ–¼èªç¾©ç›¸ä¼¼åº¦æœå°‹ç›¸é—œå…§å®¹ï¼š

```python
# æª¢ç´¢æœ€ç›¸é—œçš„ 5 å€‹æ–‡æª”ç‰‡æ®µ
results = bot.similarity_search(query, k=5)
```

### å›ç­”ç”Ÿæˆ

çµåˆæª¢ç´¢å…§å®¹ç”Ÿæˆç­”æ¡ˆï¼š

```python
prompt = f"""
åŸºæ–¼ä»¥ä¸‹å…§å®¹å›ç­”å•é¡Œï¼š

{retrieved_context}

å•é¡Œï¼š{user_question}
"""
```

## æ”¯æ´çš„æ–‡æª”æ ¼å¼

- **PDF** - `.pdf`
- **Word** - `.docx`, `.doc`
- **æ–‡æœ¬** - `.txt`
- **Markdown** - `.md`
- **HTML** - `.html`
- **CSV** - `.csv`

## é€²éšåŠŸèƒ½

### 1. è‡ªå®šç¾©æª¢ç´¢ç­–ç•¥

```python
# æ··åˆæª¢ç´¢ï¼ˆé—œéµå­— + èªç¾©ï¼‰
bot.set_retrieval_mode("hybrid")

# ç´”èªç¾©æª¢ç´¢
bot.set_retrieval_mode("semantic")

# ç´”é—œéµå­—æª¢ç´¢
bot.set_retrieval_mode("keyword")
```

### 2. å…ƒè³‡æ–™éæ¿¾

```python
# åªæœå°‹ç‰¹å®šé¡å‹çš„æ–‡æª”
response = bot.query(
    "ä»€éº¼æ˜¯æ·±åº¦å­¸ç¿’ï¼Ÿ",
    metadata_filter={"category": "æ©Ÿå™¨å­¸ç¿’", "year": 2023}
)
```

### 3. æ‰¹æ¬¡ç´¢å¼•

```python
# æ‰¹æ¬¡è™•ç†å¤šå€‹æ–‡æª”
documents = ["doc1.pdf", "doc2.pdf", "doc3.pdf"]
bot.add_documents_batch(documents, batch_size=10)
```

### 4. å¢é‡æ›´æ–°

```python
# åªç´¢å¼•æ–°æ–‡æª”
bot.update_index(incremental=True)
```

## æ•ˆèƒ½å„ªåŒ–

### 1. é¸æ“‡åˆé©çš„åˆ†å¡Šå¤§å°

- **å°å¡Š (200-300)**: ç²¾ç¢ºåº¦é«˜ï¼Œä½†å¯èƒ½éºå¤±ä¸Šä¸‹æ–‡
- **ä¸­å¡Š (500-800)**: å¹³è¡¡ç²¾ç¢ºåº¦å’Œä¸Šä¸‹æ–‡
- **å¤§å¡Š (1000+)**: ä¿ç•™å®Œæ•´ä¸Šä¸‹æ–‡ï¼Œä½†æª¢ç´¢æº–ç¢ºåº¦é™ä½

### 2. å‘é‡è³‡æ–™åº«é¸æ“‡

- **FAISS**: å¿«é€Ÿã€è¨˜æ†¶é«”æ•ˆç‡é«˜ï¼Œé©åˆæœ¬åœ°éƒ¨ç½²
- **ChromaDB**: æ˜“ç”¨ã€æ”¯æ´æŒä¹…åŒ–
- **Pinecone**: é›²ç«¯è¨—ç®¡ã€å¯æ“´å±•æ€§å¼·

### 3. å¿«å–ç­–ç•¥

```python
# å¿«å–å¸¸è¦‹å•é¡Œçš„å›ç­”
bot.enable_cache(ttl=3600)  # 1å°æ™‚éæœŸ
```

## è©•ä¼°æŒ‡æ¨™

### æª¢ç´¢å“è³ª

```python
# è¨ˆç®—æª¢ç´¢æº–ç¢ºç‡
metrics = bot.evaluate_retrieval(test_queries)
print(f"MRR: {metrics['mrr']}")  # Mean Reciprocal Rank
print(f"Recall@5: {metrics['recall_at_5']}")
```

### å›ç­”å“è³ª

- **æº–ç¢ºæ€§**: ç­”æ¡ˆæ˜¯å¦æ­£ç¢º
- **ç›¸é—œæ€§**: æ˜¯å¦å›ç­”äº†å•é¡Œ
- **ä¾†æºå¯ä¿¡åº¦**: å¼•ç”¨ä¾†æºæ˜¯å¦æº–ç¢º

## å¯¦éš›æ‡‰ç”¨å ´æ™¯

1. **ä¼æ¥­çŸ¥è­˜åº«**: å“¡å·¥æŸ¥è©¢å…¬å¸æ”¿ç­–ã€æµç¨‹
2. **æŠ€è¡“æ–‡æª”åŠ©æ‰‹**: é–‹ç™¼è€…æŸ¥è©¢ API æ–‡æª”
3. **å­¸è¡“ç ”ç©¶**: å¿«é€Ÿæª¢ç´¢è«–æ–‡å…§å®¹
4. **æ³•å¾‹è«®è©¢**: æŸ¥è©¢æ³•è¦æ¢æ–‡
5. **é†«ç™‚å•ç­”**: åŸºæ–¼é†«å­¸æ–‡ç»å›ç­”

## æŠ€è¡“æ£§

- **Python 3.8+**
- **LangChain** - RAG æ¡†æ¶
- **FAISS / ChromaDB** - å‘é‡è³‡æ–™åº«
- **OpenAI Embeddings** - æ–‡æœ¬åµŒå…¥
- **PyPDF2 / pdfplumber** - PDF è™•ç†
- **Streamlit** - Web UI

## æœ€ä½³å¯¦è¸

1. **æ–‡æª”å“è³ª**: ç¢ºä¿æ–‡æª”å…§å®¹æ¸…æ™°ã€çµæ§‹è‰¯å¥½
2. **å®šæœŸæ›´æ–°**: ä¿æŒç´¢å¼•èˆ‡æ–‡æª”åŒæ­¥
3. **æ¸¬è©¦æŸ¥è©¢**: ç”¨å¯¦éš›å•é¡Œæ¸¬è©¦æª¢ç´¢æ•ˆæœ
4. **ç›£æ§æ•ˆèƒ½**: è¿½è¹¤å›ç­”å“è³ªå’Œç”¨æˆ¶æ»¿æ„åº¦
5. **ä¾†æºé©—è­‰**: å§‹çµ‚æä¾›ä¾†æºå¼•ç”¨ä¾›ç”¨æˆ¶é©—è­‰

## æˆæ¬Š

MIT License
