# è‡ªç„¶èªè¨€è™•ç† Natural Language Processing

ğŸ”¤ ä½¿ç”¨ AI é€²è¡Œæ–‡æœ¬åˆ†æã€åˆ†é¡ã€æƒ…æ„Ÿåˆ†æå’Œèªè¨€ç†è§£

## åŠŸèƒ½ç‰¹é»

- âœ… æ–‡æœ¬åˆ†é¡
- âœ… æƒ…æ„Ÿåˆ†æ
- âœ… å‘½åå¯¦é«”è­˜åˆ¥ (NER)
- âœ… æ–‡æœ¬æ‘˜è¦
- âœ… é—œéµå­—æå–
- âœ… æ–‡æœ¬ç›¸ä¼¼åº¦
- âœ… èªè¨€ç¿»è­¯
- âœ… å•ç­”ç³»çµ±

## å°ˆæ¡ˆçµæ§‹

é€™å€‹ç›®éŒ„åŒ…å«å¤šå€‹ NLP å­å°ˆæ¡ˆå’Œå…±ç”¨å·¥å…·ï¼š

### å­å°ˆæ¡ˆï¼ˆç¨ç«‹çš„å®Œæ•´å°ˆæ¡ˆï¼‰

```
nlp/
â”œâ”€â”€ sentiment-analyzer/    # æƒ…æ„Ÿåˆ†æå™¨ï¼ˆä½¿ç”¨ Transformersï¼‰
â”œâ”€â”€ text-summarizer/       # æ–‡æœ¬æ‘˜è¦å·¥å…·ï¼ˆä½¿ç”¨ BART/T5ï¼‰
â”œâ”€â”€ spam-classifier/       # åƒåœ¾éƒµä»¶åˆ†é¡å™¨ï¼ˆå‚³çµ± MLï¼‰
â””â”€â”€ ner-extractor/         # å‘½åå¯¦é«”è­˜åˆ¥å™¨ï¼ˆspaCy/Transformersï¼‰
```

### å…±ç”¨å·¥å…·å’Œå¿«é€ŸåŸå‹

```
â”œâ”€â”€ README.md              # å°ˆæ¡ˆèªªæ˜
â”œâ”€â”€ requirements.txt       # ä¾è³´å¥—ä»¶
â”œâ”€â”€ text_classifier.py     # é€šç”¨æ–‡æœ¬åˆ†é¡å™¨
â”œâ”€â”€ sentiment_analyzer.py  # å¿«é€Ÿæƒ…æ„Ÿåˆ†æ
â”œâ”€â”€ keyword_extractor.py  # é—œéµå­—æå–
â”œâ”€â”€ app.py                # Streamlit UI
â”œâ”€â”€ models/               # æ¨¡å‹å„²å­˜
â””â”€â”€ data/                 # è³‡æ–™é›†
```

æ¯å€‹å­å°ˆæ¡ˆéƒ½åŒ…å«å®Œæ•´çš„åŠŸèƒ½ã€æ–‡æª”å’Œç¯„ä¾‹ï¼Œå¯ç¨ç«‹ä½¿ç”¨ã€‚

## å®‰è£

```bash
pip install -r requirements.txt
```

## ä½¿ç”¨æ–¹å¼

### 1. æ–‡æœ¬åˆ†é¡

```python
from text_classifier import TextClassifier

# åˆå§‹åŒ–åˆ†é¡å™¨
classifier = TextClassifier(
    model_name='distilbert-base-uncased',
    num_labels=3
)

# è¨“ç·´æ¨¡å‹
classifier.train(train_texts, train_labels, epochs=3)

# é æ¸¬
result = classifier.predict("This is a great product!")
print(f"Label: {result['label']}, Confidence: {result['confidence']:.2%}")
```

### 2. æƒ…æ„Ÿåˆ†æ

```python
from sentiment_analyzer import SentimentAnalyzer

# åˆå§‹åŒ–åˆ†æå™¨
analyzer = SentimentAnalyzer()

# åˆ†ææƒ…æ„Ÿ
sentiment = analyzer.analyze("I love this movie!")
print(f"Sentiment: {sentiment['label']} ({sentiment['score']:.2%})")

# æ‰¹æ¬¡åˆ†æ
results = analyzer.analyze_batch([
    "Great product!",
    "Terrible experience.",
    "It's okay, nothing special."
])
```

### 3. å‘½åå¯¦é«”è­˜åˆ¥

```python
from ner_extractor import NERExtractor

# åˆå§‹åŒ– NER
ner = NERExtractor()

# æå–å¯¦é«”
text = "Apple Inc. was founded by Steve Jobs in Cupertino, California."
entities = ner.extract(text)

for entity in entities:
    print(f"{entity['text']}: {entity['label']}")
# Output:
# Apple Inc.: ORG
# Steve Jobs: PER
# Cupertino: LOC
# California: LOC
```

### 4. æ–‡æœ¬æ‘˜è¦

```python
from summarizer import TextSummarizer

# åˆå§‹åŒ–æ‘˜è¦å™¨
summarizer = TextSummarizer(method='extractive')

# ç”Ÿæˆæ‘˜è¦
long_text = "..."
summary = summarizer.summarize(long_text, max_length=100)
print(summary)

# æŠ½è±¡å¼æ‘˜è¦
summarizer = TextSummarizer(method='abstractive')
summary = summarizer.summarize(long_text)
```

### 5. é—œéµå­—æå–

```python
from keyword_extractor import KeywordExtractor

extractor = KeywordExtractor()

# æå–é—œéµå­—
text = "Machine learning is a subset of artificial intelligence..."
keywords = extractor.extract(text, top_n=5)

for keyword, score in keywords:
    print(f"{keyword}: {score:.3f}")
```

### 6. æ–‡æœ¬ç›¸ä¼¼åº¦

```python
from similarity import TextSimilarity

sim = TextSimilarity()

# è¨ˆç®—ç›¸ä¼¼åº¦
text1 = "The cat sits on the mat."
text2 = "A cat is sitting on a mat."

similarity = sim.compute_similarity(text1, text2)
print(f"Similarity: {similarity:.2%}")

# æ‰¾æœ€ç›¸ä¼¼çš„æ–‡æœ¬
query = "machine learning algorithms"
documents = ["AI and ML", "deep learning models", "cooking recipes"]

most_similar = sim.find_most_similar(query, documents)
print(f"Most similar: {most_similar}")
```

### 7. Web UI

```bash
streamlit run app.py
```

## æ”¯æ´çš„æ¨¡å‹

### Transformers (Hugging Face)
- BERT
- DistilBERT
- RoBERTa
- GPT-2
- T5
- BART

### å‚³çµ± NLP æ¨¡å‹
- TF-IDF
- Word2Vec
- FastText
- spaCy

## ç¯„ä¾‹æ‡‰ç”¨

### 1. ç¤¾ç¾¤åª’é«”æƒ…æ„Ÿåˆ†æ

```python
from sentiment_analyzer import SentimentAnalyzer

analyzer = SentimentAnalyzer()

# åˆ†ææ¨æ–‡
tweets = [
    "Just bought the new iPhone, loving it! ğŸ“±",
    "Worst customer service ever ğŸ˜ ",
    "The product is okay, could be better"
]

for tweet in tweets:
    result = analyzer.analyze(tweet)
    print(f"{tweet}")
    print(f"  â†’ {result['label']}: {result['score']:.2%}\n")
```

### 2. æ–°èæ–‡ç« åˆ†é¡

```python
from text_classifier import TextClassifier

# è¨“ç·´æ–°èåˆ†é¡å™¨
classifier = TextClassifier(num_labels=4)  # Sports, Politics, Tech, Entertainment
classifier.train(news_texts, news_labels)

# åˆ†é¡æ–°æ–‡ç« 
article = "Apple announces new AI features..."
category = classifier.predict(article)
print(f"Category: {category['label']}")
```

### 3. å®¢æˆ¶è©•è«–åˆ†æ

```python
from sentiment_analyzer import SentimentAnalyzer
from keyword_extractor import KeywordExtractor

analyzer = SentimentAnalyzer()
extractor = KeywordExtractor()

review = "The battery life is amazing, but the camera quality could be better."

# æƒ…æ„Ÿåˆ†æ
sentiment = analyzer.analyze(review)

# é—œéµè©æå–
keywords = extractor.extract(review, top_n=3)

print(f"Sentiment: {sentiment['label']}")
print(f"Key aspects: {', '.join([k[0] for k in keywords])}")
```

### 4. æ™ºèƒ½å•ç­”ç³»çµ±

```python
from transformers import pipeline

qa_pipeline = pipeline("question-answering")

context = """
Python is a high-level programming language. It was created by
Guido van Rossum and first released in 1991.
"""

question = "Who created Python?"

answer = qa_pipeline(question=question, context=context)
print(f"Answer: {answer['answer']}")
print(f"Confidence: {answer['score']:.2%}")
```

## æŠ€è¡“æ£§

- **Transformers** (Hugging Face) - é è¨“ç·´æ¨¡å‹
- **spaCy** - NLP è™•ç†
- **NLTK** - è‡ªç„¶èªè¨€å·¥å…·åŒ…
- **scikit-learn** - å‚³çµ± ML
- **Gensim** - ä¸»é¡Œå»ºæ¨¡ã€Word2Vec
- **TextBlob** - ç°¡å–® NLP ä»»å‹™
- **Streamlit** - Web UI
- **PyTorch** / **TensorFlow** - æ·±åº¦å­¸ç¿’

## å¸¸è¦‹æ‡‰ç”¨å ´æ™¯

1. **å®¢æˆ¶æœå‹™**
   - è‡ªå‹•åˆ†é¡å®¢æˆ¶å•é¡Œ
   - æƒ…æ„Ÿåˆ†æå®¢æˆ¶åé¥‹
   - èŠå¤©æ©Ÿå™¨äºº

2. **å…§å®¹åˆ†æ**
   - æ–°èåˆ†é¡
   - æ–‡ç« æ‘˜è¦
   - é—œéµè©æå–

3. **ç¤¾ç¾¤åª’é«”ç›£æ§**
   - å“ç‰Œæƒ…æ„Ÿè¿½è¹¤
   - è¶¨å‹¢åˆ†æ
   - è¼¿æƒ…ç›£æ§

4. **æ–‡æª”è™•ç†**
   - è‡ªå‹•æ¨™è¨˜
   - è³‡è¨Šæå–
   - æ–‡æª”æœå°‹

5. **ç¿»è­¯æœå‹™**
   - å¤šèªè¨€ç¿»è­¯
   - èªè¨€æª¢æ¸¬
   - æ–‡æœ¬æœ¬åœ°åŒ–

## æ•ˆèƒ½å„ªåŒ–

- ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹ï¼ˆDistilBERTï¼‰åŠ å¿«æ¨ç†
- æ‰¹æ¬¡è™•ç†æé«˜ååé‡
- GPU åŠ é€Ÿ
- æ¨¡å‹é‡åŒ–
- å¿«å–å¸¸è¦‹çµæœ

## æœ€ä½³å¯¦è¸

1. **è³‡æ–™æº–å‚™**
   - æ¸…ç†å’Œæ¨™æº–åŒ–æ–‡æœ¬
   - è™•ç†ç‰¹æ®Šå­—ç¬¦å’Œè¡¨æƒ…ç¬¦è™Ÿ
   - å¹³è¡¡è¨“ç·´è³‡æ–™

2. **æ¨¡å‹é¸æ“‡**
   - å¾é è¨“ç·´æ¨¡å‹é–‹å§‹
   - æ ¹æ“šä»»å‹™é¸æ“‡é©ç•¶çš„æ¨¡å‹å¤§å°
   - è€ƒæ…®å»¶é²å’Œæº–ç¢ºæ€§çš„æ¬Šè¡¡

3. **è©•ä¼°**
   - ä½¿ç”¨å¤šå€‹æŒ‡æ¨™
   - æ¸¬è©¦é‚Šç·£æ¡ˆä¾‹
   - æŒçºŒç›£æ§æ€§èƒ½

## å­å°ˆæ¡ˆä»‹ç´¹

### 1. sentiment-analyzer (æƒ…æ„Ÿåˆ†æå™¨)
åŠŸèƒ½å®Œæ•´çš„æƒ…æ„Ÿåˆ†æå·¥å…·ï¼Œä½¿ç”¨ Hugging Face Transformersã€‚
- æ”¯æ´å¤šèªè¨€æƒ…æ„Ÿåˆ†æ
- æä¾› CLI å’Œ API ä»‹é¢
- æ‰¹é‡è™•ç†æ”¯æ´
- è©³ç´°æ–‡æª”å’Œç¯„ä¾‹

æŸ¥çœ‹ `sentiment-analyzer/README.md` äº†è§£æ›´å¤šã€‚

### 2. text-summarizer (æ–‡æœ¬æ‘˜è¦å·¥å…·)
è‡ªå‹•ç”Ÿæˆæ–‡æœ¬æ‘˜è¦çš„å·¥å…·ã€‚
- ä½¿ç”¨ BART/T5 ç­‰å…ˆé€²æ¨¡å‹
- æ”¯æ´é•·æ–‡æœ¬åˆ†æ®µæ‘˜è¦
- å¯èª¿æ•´æ‘˜è¦é•·åº¦å’Œæ¯”ä¾‹
- REST API æœå‹™

æŸ¥çœ‹ `text-summarizer/README.md` äº†è§£æ›´å¤šã€‚

### 3. spam-classifier (åƒåœ¾éƒµä»¶åˆ†é¡å™¨)
åŸºæ–¼å‚³çµ±æ©Ÿå™¨å­¸ç¿’çš„åƒåœ¾éƒµä»¶éæ¿¾å™¨ã€‚
- ä½¿ç”¨ TF-IDF + æ©Ÿå™¨å­¸ç¿’
- æ”¯æ´å¤šç¨®åˆ†é¡ç®—æ³•ï¼ˆNB, LR, RF, SVMï¼‰
- å¯è¨“ç·´è‡ªå®šç¾©æ•¸æ“šé›†
- æ¨¡å‹ä¿å­˜å’Œè¼‰å…¥åŠŸèƒ½

æŸ¥çœ‹ `spam-classifier/README.md` äº†è§£æ›´å¤šã€‚

### 4. ner-extractor (å‘½åå¯¦é«”è­˜åˆ¥å™¨)
æå–æ–‡æœ¬ä¸­çš„å‘½åå¯¦é«”ï¼ˆäººåã€åœ°åã€çµ„ç¹”ç­‰ï¼‰ã€‚
- æ”¯æ´ spaCy å’Œ Transformers å…©ç¨®å¾Œç«¯
- å¯¦é«”å¯è¦–åŒ–åŠŸèƒ½
- æ‰¹é‡è™•ç†æ”¯æ´
- å¯¦é«”é¡å‹éæ¿¾

æŸ¥çœ‹ `ner-extractor/README.md` äº†è§£æ›´å¤šã€‚

## æˆæ¬Š

MIT License
