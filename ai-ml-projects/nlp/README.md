# è‡ªç„¶èªè¨€è™•ç† Natural Language Processing

ğŸ”¤ ä½¿ç”¨ AI é€²è¡Œæ–‡æœ¬åˆ†æã€åˆ†é¡ã€æƒ…æ„Ÿåˆ†æå’Œèªè¨€ç†è§£

## åŠŸèƒ½ç‰¹é»

- âœ… **æ–‡æœ¬åˆ†é¡** - ä½¿ç”¨ Transformers é€²è¡Œå¤šé¡åˆ¥åˆ†é¡
- âœ… **æƒ…æ„Ÿåˆ†æ** - æ­£é¢/è² é¢æƒ…æ„Ÿæª¢æ¸¬
- âœ… **æƒ…ç·’æª¢æ¸¬** - ç´°ç·»æƒ…ç·’è­˜åˆ¥ (å–œæ‚…ã€æ‚²å‚·ã€æ†¤æ€’ç­‰)
- âœ… **å‘½åå¯¦é«”è­˜åˆ¥ (NER)** - æå–äººåã€åœ°åã€çµ„ç¹”ç­‰
- âœ… **æ–‡æœ¬æ‘˜è¦** - æŠ½å–å¼å’Œç”Ÿæˆå¼æ‘˜è¦
- âœ… **é—œéµå­—æå–** - å¤šç¨®æ¼”ç®—æ³• (TF-IDF, RAKE, TextRank, KeyBERT)
- âœ… **æ–‡æœ¬ç›¸ä¼¼åº¦** - å¤šç¨®ç›¸ä¼¼åº¦è¨ˆç®—æ–¹æ³•
- âœ… **èªè¨€åµæ¸¬** - æ”¯æ´ 11 ç¨®èªè¨€çš„è‡ªå‹•åµæ¸¬
- âœ… **å•ç­”ç³»çµ±** - åŸºæ–¼ä¸Šä¸‹æ–‡çš„æ™ºèƒ½å•ç­”
- âœ… **é›¶æ¨£æœ¬åˆ†é¡** - ç„¡éœ€è¨“ç·´è³‡æ–™çš„åˆ†é¡
- âœ… **åƒåœ¾éƒµä»¶æª¢æ¸¬** - å‚³çµ± ML æ–¹æ³•

## å°ˆæ¡ˆçµæ§‹

é€™å€‹ç›®éŒ„åŒ…å«å¤šå€‹ NLP å­å°ˆæ¡ˆå’Œå…±ç”¨å·¥å…·ï¼š

### å­å°ˆæ¡ˆï¼ˆç¨ç«‹çš„å®Œæ•´å°ˆæ¡ˆï¼‰

```
nlp/
â”œâ”€â”€ sentiment-analyzer/    # æƒ…æ„Ÿåˆ†æå™¨ï¼ˆä½¿ç”¨ Transformersï¼‰
â”œâ”€â”€ text-summarizer/       # æ–‡æœ¬æ‘˜è¦å·¥å…·ï¼ˆä½¿ç”¨ BART/T5ï¼‰
â”œâ”€â”€ spam-classifier/       # åƒåœ¾éƒµä»¶åˆ†é¡å™¨ï¼ˆå‚³çµ± MLï¼‰
â””â”€â”€ ner-extractor/         # å‘½åå¯¦é«”è­˜åˆ¥å™¨ï¼ˆspaCy/Transformersï¼‰
```

### å…±ç”¨å·¥å…·å’Œå¿«é€ŸåŸå‹

```
â”œâ”€â”€ README.md              # å°ˆæ¡ˆèªªæ˜
â”œâ”€â”€ requirements.txt       # ä¾è³´å¥—ä»¶
â”œâ”€â”€ text_classifier.py     # é€šç”¨æ–‡æœ¬åˆ†é¡å™¨
â”œâ”€â”€ sentiment_analyzer.py  # å¿«é€Ÿæƒ…æ„Ÿåˆ†æ
â”œâ”€â”€ keyword_extractor.py   # ğŸ†• é€²éšé—œéµå­—æå– (RAKE, TextRank, KeyBERT)
â”œâ”€â”€ text_similarity.py     # ğŸ†• æ–‡æœ¬ç›¸ä¼¼åº¦æ¯”è¼ƒå·¥å…·
â”œâ”€â”€ qa_system.py           # ğŸ†• å•ç­”ç³»çµ±
â”œâ”€â”€ language_detector.py   # ğŸ†• èªè¨€åµæ¸¬å·¥å…·
â”œâ”€â”€ zero_shot_classifier.py # ğŸ†• é›¶æ¨£æœ¬åˆ†é¡å™¨
â”œâ”€â”€ emotion_detector.py    # ğŸ†• æƒ…ç·’æª¢æ¸¬å™¨
â”œâ”€â”€ app.py                 # Streamlit UI
â”œâ”€â”€ models/                # æ¨¡å‹å„²å­˜
â””â”€â”€ data/                  # è³‡æ–™é›†
```

æ¯å€‹å­å°ˆæ¡ˆéƒ½åŒ…å«å®Œæ•´çš„åŠŸèƒ½ã€æ–‡æª”å’Œç¯„ä¾‹ï¼Œå¯ç¨ç«‹ä½¿ç”¨ã€‚

## ğŸ†• æ–°å¢åŠŸèƒ½äº®é»

### 1. é€²éšé—œéµå­—æå– (keyword_extractor.py)
- **å¤šç¨®æ¼”ç®—æ³•**ï¼šTF-IDFã€RAKEã€TextRankã€KeyBERT
- **AI å¢å¼·**ï¼šå¯é¸çš„ BERT èªç¾©é—œéµå­—æå–
- **æ–¹æ³•æ¯”è¼ƒ**ï¼šä¸€éµæ¯”è¼ƒæ‰€æœ‰æ–¹æ³•çš„æ•ˆæœ
- **ä¸Šä¸‹æ–‡æå–**ï¼šé¡¯ç¤ºé—œéµå­—å‡ºç¾çš„ä¸Šä¸‹æ–‡

### 2. æ–‡æœ¬ç›¸ä¼¼åº¦åˆ†æ (text_similarity.py)
- **å¤šç¨®ç›¸ä¼¼åº¦æ–¹æ³•**ï¼šCosineã€Jaccardã€Levenshteinã€N-gram
- **èªç¾©ç›¸ä¼¼åº¦**ï¼šåŸºæ–¼ BERT çš„èªç¾©æ¯”å°ï¼ˆå¯é¸ï¼‰
- **æ–‡æª”æœå°‹**ï¼šå¾æ–‡æª”é›†åˆä¸­æ‰¾å‡ºæœ€ç›¸ä¼¼çš„æ–‡æœ¬
- **é‡è¤‡æª¢æ¸¬**ï¼šè‡ªå‹•åµæ¸¬è¿‘ä¼¼é‡è¤‡çš„æ–‡æœ¬
- **ç›¸ä¼¼åº¦çŸ©é™£**ï¼šè¨ˆç®—å¤šå€‹æ–‡æœ¬ä¹‹é–“çš„å…©å…©ç›¸ä¼¼åº¦

### 3. å•ç­”ç³»çµ± (qa_system.py)
- **æå–å¼å•ç­”**ï¼šå¾ä¸Šä¸‹æ–‡ä¸­æå–ç²¾ç¢ºç­”æ¡ˆ
- **å¤šæ–‡æª”å•ç­”**ï¼šè·¨å¤šå€‹æ–‡æª”æœå°‹ç­”æ¡ˆ
- **å°è©±å¼å•ç­”**ï¼šç¶­æŒä¸Šä¸‹æ–‡çš„é€£çºŒå•ç­”
- **ç­”æ¡ˆé©—è­‰**ï¼šé©—è­‰çµ¦å®šç­”æ¡ˆçš„æ­£ç¢ºæ€§
- **æ‰¹æ¬¡è™•ç†**ï¼šä¸€æ¬¡è™•ç†å¤šå€‹å•é¡Œ

### 4. èªè¨€åµæ¸¬ (language_detector.py)
- **11 ç¨®èªè¨€æ”¯æ´**ï¼šEN, ES, FR, DE, IT, PT, ZH, JA, KO, RU, AR
- **å¤šç¨®æª¢æ¸¬æ–¹æ³•**ï¼šè…³æœ¬æª¢æ¸¬ã€è©å½™æ¯”å°ã€å­—å…ƒé »ç‡
- **æ··åˆèªè¨€åˆ†æ**ï¼šåˆ†æåŒ…å«å¤šç¨®èªè¨€çš„æ–‡æœ¬
- **80%+ æº–ç¢ºç‡**ï¼šç‰¹åˆ¥æ˜¯å°éæ‹‰ä¸å­—æ¯èªè¨€
- **æ‰¹æ¬¡è™•ç†**ï¼šé«˜æ•ˆè™•ç†å¤§é‡æ–‡æœ¬

### 5. é›¶æ¨£æœ¬åˆ†é¡ (zero_shot_classifier.py)
- **ç„¡éœ€è¨“ç·´**ï¼šä¸éœ€è¦è¨“ç·´è³‡æ–™å³å¯åˆ†é¡
- **å‹•æ…‹é¡åˆ¥**ï¼šå¯éš¨æ™‚æ›´æ”¹åˆ†é¡é¡åˆ¥
- **å¤šæ¨™ç±¤æ”¯æ´**ï¼šä¸€å€‹æ–‡æœ¬å¯å±¬æ–¼å¤šå€‹é¡åˆ¥
- **éšå±¤å¼åˆ†é¡**ï¼šæ”¯æ´å¤šå±¤æ¬¡åˆ†é¡çµæ§‹
- **è‡ªè¨‚å‡è¨­æ¨¡æ¿**ï¼šéˆæ´»çš„åˆ†é¡é‚è¼¯

### 6. æƒ…ç·’æª¢æ¸¬ (emotion_detector.py)
- **ç´°ç·»æƒ…ç·’**ï¼šjoy, sadness, anger, fear, surprise, love, disgust
- **æƒ…ç·’å¼·åº¦**ï¼šåˆ†ææƒ…ç·’çš„å¼·çƒˆç¨‹åº¦
- **å°è©±åˆ†æ**ï¼šè¿½è¹¤å°è©±ä¸­çš„æƒ…ç·’è®ŠåŒ–è»Œè·¡
- **æƒ…ç·’åˆ†ä½ˆ**ï¼šçµ±è¨ˆå¤šå€‹æ–‡æœ¬çš„æƒ…ç·’åˆ†ä½ˆ
- **ç¤¾ç¾¤åª’é«”ç›£æ§**ï¼šé©ç”¨æ–¼å³æ™‚æƒ…ç·’åˆ†æ

## å®‰è£

```bash
pip install -r requirements.txt
```

## ä½¿ç”¨æ–¹å¼

### 1. æ–‡æœ¬åˆ†é¡

```python
from text_classifier import TextClassifier

# åˆå§‹åŒ–åˆ†é¡å™¨
classifier = TextClassifier(
    model_name='distilbert-base-uncased',
    num_labels=3
)

# è¨“ç·´æ¨¡å‹
classifier.train(train_texts, train_labels, epochs=3)

# é æ¸¬
result = classifier.predict("This is a great product!")
print(f"Label: {result['label']}, Confidence: {result['confidence']:.2%}")
```

### 2. æƒ…æ„Ÿåˆ†æ

```python
from sentiment_analyzer import SentimentAnalyzer

# åˆå§‹åŒ–åˆ†æå™¨
analyzer = SentimentAnalyzer()

# åˆ†ææƒ…æ„Ÿ
sentiment = analyzer.analyze("I love this movie!")
print(f"Sentiment: {sentiment['label']} ({sentiment['score']:.2%})")

# æ‰¹æ¬¡åˆ†æ
results = analyzer.analyze_batch([
    "Great product!",
    "Terrible experience.",
    "It's okay, nothing special."
])
```

### 3. å‘½åå¯¦é«”è­˜åˆ¥

```python
from ner_extractor import NERExtractor

# åˆå§‹åŒ– NER
ner = NERExtractor()

# æå–å¯¦é«”
text = "Apple Inc. was founded by Steve Jobs in Cupertino, California."
entities = ner.extract(text)

for entity in entities:
    print(f"{entity['text']}: {entity['label']}")
# Output:
# Apple Inc.: ORG
# Steve Jobs: PER
# Cupertino: LOC
# California: LOC
```

### 4. æ–‡æœ¬æ‘˜è¦

```python
from summarizer import TextSummarizer

# åˆå§‹åŒ–æ‘˜è¦å™¨
summarizer = TextSummarizer(method='extractive')

# ç”Ÿæˆæ‘˜è¦
long_text = "..."
summary = summarizer.summarize(long_text, max_length=100)
print(summary)

# æŠ½è±¡å¼æ‘˜è¦
summarizer = TextSummarizer(method='abstractive')
summary = summarizer.summarize(long_text)
```

### 5. é—œéµå­—æå–ï¼ˆé€²éšç‰ˆï¼‰

```python
from keyword_extractor import KeywordExtractor

# åŸºç¤ä½¿ç”¨
extractor = KeywordExtractor()

text = """
Machine learning is a subset of artificial intelligence that focuses on
the development of algorithms and statistical models. Deep learning uses
neural networks with multiple layers.
"""

# TF-IDF æå–
keywords = extractor.extract(text, top_n=5, method='tfidf')

# RAKE æ¼”ç®—æ³•ï¼ˆé©åˆæå–çŸ­èªï¼‰
phrases = extractor.extract_rake(text, top_n=5)

# TextRank æ¼”ç®—æ³•ï¼ˆåŸºæ–¼åœ–ï¼‰
keywords = extractor.extract_textrank(text, top_n=5)

# æ¯”è¼ƒæ‰€æœ‰æ–¹æ³•
extractor.compare_methods(text, top_n=5)

# AI å¢å¼·ç‰ˆï¼ˆéœ€è¦é¡å¤–å®‰è£ï¼‰
ai_extractor = KeywordExtractor(use_ai=True)
keywords = ai_extractor.extract_keybert(text, top_n=5, diversity=0.7)
```

### 6. æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆå…¨æ–°å·¥å…·ï¼‰

```python
from text_similarity import TextSimilarity

analyzer = TextSimilarity()

text1 = "Machine learning is a branch of artificial intelligence."
text2 = "Machine learning is a subset of AI."

# å¤šç¨®ç›¸ä¼¼åº¦æ–¹æ³•
similarities = analyzer.compute_all_similarities(text1, text2)
# è¿”å›: {'cosine_tfidf': 0.34, 'jaccard': 0.38, 'levenshtein': 0.57, ...}

# æ–‡æª”æœå°‹
documents = [
    "Machine learning is transforming the world.",
    "Python is a popular programming language.",
    "Deep learning is a subset of machine learning.",
]
query = "What is machine learning?"
results = analyzer.find_most_similar(query, documents, top_k=2)

# é‡è¤‡æª¢æ¸¬
texts = ["Text 1", "Text 1", "Different text"]
duplicates = analyzer.find_duplicates(texts, threshold=0.9)

# AI èªç¾©ç›¸ä¼¼åº¦ï¼ˆå¯é¸ï¼‰
ai_analyzer = TextSimilarity(use_ai=True)
semantic_sim = ai_analyzer.semantic_similarity(text1, text2)
```

### 7. å•ç­”ç³»çµ±ï¼ˆå…¨æ–°ï¼‰

```python
from qa_system import QuestionAnsweringSystem

qa = QuestionAnsweringSystem()

context = """
Python is a high-level programming language. It was created by
Guido van Rossum and first released in 1991.
"""

# å–®å€‹å•é¡Œ
answer = qa.answer("Who created Python?", context)
print(answer['best_answer'])  # "Guido van Rossum"
print(answer['confidence'])   # 0.95

# å¤šæ–‡æª”å•ç­”
contexts = [context1, context2, context3]
answers = qa.answer_multiple_contexts(question, contexts, top_k=3)

# å°è©±å¼å•ç­”
questions = ["What is Python?", "Who created it?", "When was it released?"]
conversation = qa.ask_conversational(questions, context)
```

### 8. èªè¨€åµæ¸¬ï¼ˆå…¨æ–°ï¼‰

```python
from language_detector import LanguageDetector

detector = LanguageDetector()

# åµæ¸¬å–®ä¸€æ–‡æœ¬
result = detector.detect_combined("Bonjour le monde!")
print(result['language'])    # 'fr'
print(result['confidence'])  # 0.87

# æ‰¹æ¬¡è™•ç†
texts = [
    "Hello world!",
    "Hola mundo!",
    "Bonjour le monde!",
    "è¿™æ˜¯ä¸­æ–‡"
]
results = detector.detect_batch(texts)

# æ··åˆèªè¨€åˆ†æ
mixed = "Hello ä¸–ç•Œ! This is mixed text. æ—¥æœ¬èªã‚‚å«ã‚€ã€‚"
scripts = detector.detect_script(mixed)
# {'latin': 0.67, 'japanese': 0.18, 'chinese': 0.15}
```

### 9. é›¶æ¨£æœ¬åˆ†é¡ï¼ˆå…¨æ–°ï¼‰

```python
from zero_shot_classifier import ZeroShotClassifier

classifier = ZeroShotClassifier()

text = "Apple announced its latest iPhone with improved camera."

# æ–°èåˆ†é¡ï¼ˆç„¡éœ€è¨“ç·´ï¼‰
categories = ["technology", "sports", "politics", "entertainment"]
result = classifier.classify(text, categories)
print(result['best_label'])  # 'technology'

# å¤šæ¨™ç±¤åˆ†é¡
movie = "An action-packed sci-fi thriller with dramatic moments."
genres = ["action", "drama", "science fiction", "comedy", "romance"]
result = classifier.classify(movie, genres, multi_label=True)

# éšå±¤å¼åˆ†é¡
hierarchy = {
    "science": ["biology", "physics", "chemistry"],
    "business": ["finance", "marketing", "management"]
}
result = classifier.hierarchical_classify(text, hierarchy)
```

### 10. æƒ…ç·’æª¢æ¸¬ï¼ˆå…¨æ–°ï¼‰

```python
from emotion_detector import EmotionDetector

detector = EmotionDetector()

# åŸºæœ¬æƒ…ç·’æª¢æ¸¬
text = "I'm so happy and excited about this!"
result = detector.detect(text, top_k=3)
print(result['primary_emotion'])  # 'joy'
print(result['confidence'])       # 0.94

# æƒ…ç·’å¼·åº¦
emotion, intensity = detector.get_emotion_intensity(text)
# ('joy', 'very strong')

# å°è©±æƒ…ç·’åˆ†æ
conversation = [
    "Hi! I'm so excited!",
    "I have a question.",
    "I'm getting frustrated.",
    "Oh wait, I found the solution!",
    "Yes! It works!"
]
analysis = detector.analyze_conversation(conversation)
print(analysis['emotional_arc'])
print(analysis['dominant_emotion'])

# æ‰¹æ¬¡è™•ç†
reviews = ["Great product!", "Terrible quality.", "It's okay."]
results = detector.detect_batch(reviews)
```

### 11. Web UI

```bash
streamlit run app.py
```

## æ”¯æ´çš„æ¨¡å‹

### Transformers (Hugging Face)
- BERT
- DistilBERT
- RoBERTa
- GPT-2
- T5
- BART

### å‚³çµ± NLP æ¨¡å‹
- TF-IDF
- Word2Vec
- FastText
- spaCy

## ç¯„ä¾‹æ‡‰ç”¨

### 1. ç¤¾ç¾¤åª’é«”æƒ…æ„Ÿåˆ†æ

```python
from sentiment_analyzer import SentimentAnalyzer

analyzer = SentimentAnalyzer()

# åˆ†ææ¨æ–‡
tweets = [
    "Just bought the new iPhone, loving it! ğŸ“±",
    "Worst customer service ever ğŸ˜ ",
    "The product is okay, could be better"
]

for tweet in tweets:
    result = analyzer.analyze(tweet)
    print(f"{tweet}")
    print(f"  â†’ {result['label']}: {result['score']:.2%}\n")
```

### 2. æ–°èæ–‡ç« åˆ†é¡

```python
from text_classifier import TextClassifier

# è¨“ç·´æ–°èåˆ†é¡å™¨
classifier = TextClassifier(num_labels=4)  # Sports, Politics, Tech, Entertainment
classifier.train(news_texts, news_labels)

# åˆ†é¡æ–°æ–‡ç« 
article = "Apple announces new AI features..."
category = classifier.predict(article)
print(f"Category: {category['label']}")
```

### 3. å®¢æˆ¶è©•è«–åˆ†æ

```python
from sentiment_analyzer import SentimentAnalyzer
from keyword_extractor import KeywordExtractor

analyzer = SentimentAnalyzer()
extractor = KeywordExtractor()

review = "The battery life is amazing, but the camera quality could be better."

# æƒ…æ„Ÿåˆ†æ
sentiment = analyzer.analyze(review)

# é—œéµè©æå–
keywords = extractor.extract(review, top_n=3)

print(f"Sentiment: {sentiment['label']}")
print(f"Key aspects: {', '.join([k[0] for k in keywords])}")
```

### 4. æ™ºèƒ½å•ç­”ç³»çµ±

```python
from transformers import pipeline

qa_pipeline = pipeline("question-answering")

context = """
Python is a high-level programming language. It was created by
Guido van Rossum and first released in 1991.
"""

question = "Who created Python?"

answer = qa_pipeline(question=question, context=context)
print(f"Answer: {answer['answer']}")
print(f"Confidence: {answer['score']:.2%}")
```

## æŠ€è¡“æ£§

- **Transformers** (Hugging Face) - é è¨“ç·´æ¨¡å‹
- **spaCy** - NLP è™•ç†
- **NLTK** - è‡ªç„¶èªè¨€å·¥å…·åŒ…
- **scikit-learn** - å‚³çµ± ML
- **Gensim** - ä¸»é¡Œå»ºæ¨¡ã€Word2Vec
- **TextBlob** - ç°¡å–® NLP ä»»å‹™
- **Streamlit** - Web UI
- **PyTorch** / **TensorFlow** - æ·±åº¦å­¸ç¿’

## å¸¸è¦‹æ‡‰ç”¨å ´æ™¯

1. **å®¢æˆ¶æœå‹™**
   - è‡ªå‹•åˆ†é¡å®¢æˆ¶å•é¡Œ
   - æƒ…æ„Ÿåˆ†æå®¢æˆ¶åé¥‹
   - èŠå¤©æ©Ÿå™¨äºº

2. **å…§å®¹åˆ†æ**
   - æ–°èåˆ†é¡
   - æ–‡ç« æ‘˜è¦
   - é—œéµè©æå–

3. **ç¤¾ç¾¤åª’é«”ç›£æ§**
   - å“ç‰Œæƒ…æ„Ÿè¿½è¹¤
   - è¶¨å‹¢åˆ†æ
   - è¼¿æƒ…ç›£æ§

4. **æ–‡æª”è™•ç†**
   - è‡ªå‹•æ¨™è¨˜
   - è³‡è¨Šæå–
   - æ–‡æª”æœå°‹

5. **ç¿»è­¯æœå‹™**
   - å¤šèªè¨€ç¿»è­¯
   - èªè¨€æª¢æ¸¬
   - æ–‡æœ¬æœ¬åœ°åŒ–

## æ•ˆèƒ½å„ªåŒ–

- ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹ï¼ˆDistilBERTï¼‰åŠ å¿«æ¨ç†
- æ‰¹æ¬¡è™•ç†æé«˜ååé‡
- GPU åŠ é€Ÿ
- æ¨¡å‹é‡åŒ–
- å¿«å–å¸¸è¦‹çµæœ

## æœ€ä½³å¯¦è¸

1. **è³‡æ–™æº–å‚™**
   - æ¸…ç†å’Œæ¨™æº–åŒ–æ–‡æœ¬
   - è™•ç†ç‰¹æ®Šå­—ç¬¦å’Œè¡¨æƒ…ç¬¦è™Ÿ
   - å¹³è¡¡è¨“ç·´è³‡æ–™

2. **æ¨¡å‹é¸æ“‡**
   - å¾é è¨“ç·´æ¨¡å‹é–‹å§‹
   - æ ¹æ“šä»»å‹™é¸æ“‡é©ç•¶çš„æ¨¡å‹å¤§å°
   - è€ƒæ…®å»¶é²å’Œæº–ç¢ºæ€§çš„æ¬Šè¡¡

3. **è©•ä¼°**
   - ä½¿ç”¨å¤šå€‹æŒ‡æ¨™
   - æ¸¬è©¦é‚Šç·£æ¡ˆä¾‹
   - æŒçºŒç›£æ§æ€§èƒ½

## å­å°ˆæ¡ˆä»‹ç´¹

### 1. sentiment-analyzer (æƒ…æ„Ÿåˆ†æå™¨)
åŠŸèƒ½å®Œæ•´çš„æƒ…æ„Ÿåˆ†æå·¥å…·ï¼Œä½¿ç”¨ Hugging Face Transformersã€‚
- æ”¯æ´å¤šèªè¨€æƒ…æ„Ÿåˆ†æ
- æä¾› CLI å’Œ API ä»‹é¢
- æ‰¹é‡è™•ç†æ”¯æ´
- è©³ç´°æ–‡æª”å’Œç¯„ä¾‹

æŸ¥çœ‹ `sentiment-analyzer/README.md` äº†è§£æ›´å¤šã€‚

### 2. text-summarizer (æ–‡æœ¬æ‘˜è¦å·¥å…·)
è‡ªå‹•ç”Ÿæˆæ–‡æœ¬æ‘˜è¦çš„å·¥å…·ã€‚
- ä½¿ç”¨ BART/T5 ç­‰å…ˆé€²æ¨¡å‹
- æ”¯æ´é•·æ–‡æœ¬åˆ†æ®µæ‘˜è¦
- å¯èª¿æ•´æ‘˜è¦é•·åº¦å’Œæ¯”ä¾‹
- REST API æœå‹™

æŸ¥çœ‹ `text-summarizer/README.md` äº†è§£æ›´å¤šã€‚

### 3. spam-classifier (åƒåœ¾éƒµä»¶åˆ†é¡å™¨)
åŸºæ–¼å‚³çµ±æ©Ÿå™¨å­¸ç¿’çš„åƒåœ¾éƒµä»¶éæ¿¾å™¨ã€‚
- ä½¿ç”¨ TF-IDF + æ©Ÿå™¨å­¸ç¿’
- æ”¯æ´å¤šç¨®åˆ†é¡ç®—æ³•ï¼ˆNB, LR, RF, SVMï¼‰
- å¯è¨“ç·´è‡ªå®šç¾©æ•¸æ“šé›†
- æ¨¡å‹ä¿å­˜å’Œè¼‰å…¥åŠŸèƒ½

æŸ¥çœ‹ `spam-classifier/README.md` äº†è§£æ›´å¤šã€‚

### 4. ner-extractor (å‘½åå¯¦é«”è­˜åˆ¥å™¨)
æå–æ–‡æœ¬ä¸­çš„å‘½åå¯¦é«”ï¼ˆäººåã€åœ°åã€çµ„ç¹”ç­‰ï¼‰ã€‚
- æ”¯æ´ spaCy å’Œ Transformers å…©ç¨®å¾Œç«¯
- å¯¦é«”å¯è¦–åŒ–åŠŸèƒ½
- æ‰¹é‡è™•ç†æ”¯æ´
- å¯¦é«”é¡å‹éæ¿¾

æŸ¥çœ‹ `ner-extractor/README.md` äº†è§£æ›´å¤šã€‚

## æˆæ¬Š

MIT License
