# è³‡æ–™åˆ†æèˆ‡é æ¸¬ Data Analysis

ğŸ“Š ä½¿ç”¨æ©Ÿå™¨å­¸ç¿’é€²è¡Œè³‡æ–™åˆ†æã€è¦–è¦ºåŒ–å’Œé æ¸¬å»ºæ¨¡

## åŠŸèƒ½ç‰¹é»

- âœ… è³‡æ–™æ¢ç´¢èˆ‡è¦–è¦ºåŒ–
- âœ… çµ±è¨ˆåˆ†æ
- âœ… é æ¸¬å»ºæ¨¡ (å›æ­¸ã€åˆ†é¡)
- âœ… æ™‚é–“åºåˆ—åˆ†æ
- âœ… ç‰¹å¾µå·¥ç¨‹
- âœ… æ¨¡å‹è©•ä¼°èˆ‡æ¯”è¼ƒ
- âœ… äº’å‹•å¼å ±å‘Š
- âœ… è‡ªå‹•åŒ– ML (AutoML)

## å°ˆæ¡ˆçµæ§‹

```
data-analysis/
â”œâ”€â”€ README.md              # å°ˆæ¡ˆèªªæ˜
â”œâ”€â”€ requirements.txt       # ä¾è³´å¥—ä»¶
â”œâ”€â”€ analyzer.py           # è³‡æ–™åˆ†æå™¨
â”œâ”€â”€ predictor.py          # é æ¸¬æ¨¡å‹
â”œâ”€â”€ visualizer.py         # è¦–è¦ºåŒ–å·¥å…·
â”œâ”€â”€ time_series.py        # æ™‚é–“åºåˆ—åˆ†æ
â”œâ”€â”€ feature_engineering.py # ç‰¹å¾µå·¥ç¨‹
â”œâ”€â”€ app.py                # Streamlit UI
â”œâ”€â”€ notebooks/            # Jupyter Notebooks
â”‚   â””â”€â”€ exploratory_analysis.ipynb
â”œâ”€â”€ data/                 # è³‡æ–™é›†
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ sample_data.csv
â””â”€â”€ models/               # è¨“ç·´å¥½çš„æ¨¡å‹
```

## å®‰è£

```bash
pip install -r requirements.txt
```

## ä½¿ç”¨æ–¹å¼

### 1. è³‡æ–™æ¢ç´¢èˆ‡åˆ†æ

```python
from analyzer import DataAnalyzer

# è¼‰å…¥è³‡æ–™
analyzer = DataAnalyzer('data/dataset.csv')

# åŸºæœ¬çµ±è¨ˆ
stats = analyzer.describe()
print(stats)

# æª¢æŸ¥ç¼ºå¤±å€¼
missing = analyzer.check_missing()

# ç›¸é—œæ€§åˆ†æ
correlation = analyzer.correlation_analysis()

# è‡ªå‹• EDA å ±å‘Š
analyzer.generate_report(output='report.html')
```

### 2. é æ¸¬å»ºæ¨¡

```python
from predictor import Predictor

# åˆå§‹åŒ–é æ¸¬å™¨
predictor = Predictor(task='classification')  # æˆ– 'regression'

# è¨“ç·´æ¨¡å‹
predictor.train(
    X_train, y_train,
    model_type='random_forest',
    cv=5
)

# é æ¸¬
predictions = predictor.predict(X_test)

# è©•ä¼°
metrics = predictor.evaluate(X_test, y_test)
print(f"Accuracy: {metrics['accuracy']:.2%}")

# ç‰¹å¾µé‡è¦æ€§
importance = predictor.feature_importance()
```

### 3. è¦–è¦ºåŒ–

```python
from visualizer import DataVisualizer

viz = DataVisualizer(df)

# åˆ†ä½ˆåœ–
viz.plot_distribution('age')

# æ•£é»åœ–çŸ©é™£
viz.scatter_matrix(['age', 'income', 'score'])

# ç›¸é—œæ€§ç†±åœ–
viz.correlation_heatmap()

# æ™‚é–“åºåˆ—åœ–
viz.time_series_plot('date', 'value')
```

### 4. æ™‚é–“åºåˆ—åˆ†æ

```python
from time_series import TimeSeriesAnalyzer

ts = TimeSeriesAnalyzer(data, date_column='date')

# è¶¨å‹¢åˆ†æ
trend = ts.analyze_trend()

# å­£ç¯€æ€§åˆ†è§£
decomposition = ts.seasonal_decompose()

# é æ¸¬
forecast = ts.forecast(periods=30, method='arima')

# è¦–è¦ºåŒ–
ts.plot_forecast(forecast)
```

### 5. Web UI

```bash
streamlit run app.py
```

## æ”¯æ´çš„æ¨¡å‹

### åˆ†é¡æ¨¡å‹
- Logistic Regression
- Random Forest Classifier
- Gradient Boosting (XGBoost, LightGBM)
- Support Vector Machine
- Neural Networks

### å›æ­¸æ¨¡å‹
- Linear Regression
- Random Forest Regressor
- Gradient Boosting Regressor
- Support Vector Regression
- Neural Networks

### æ™‚é–“åºåˆ—æ¨¡å‹
- ARIMA
- Prophet
- LSTM
- Exponential Smoothing

## è³‡æ–™é›†ç¯„ä¾‹

å°ˆæ¡ˆåŒ…å«ä»¥ä¸‹ç¯„ä¾‹è³‡æ–™é›†ï¼š

1. **customer_data.csv** - å®¢æˆ¶è³‡æ–™èˆ‡è³¼è²·è¡Œç‚º
2. **sales_time_series.csv** - éŠ·å”®æ™‚é–“åºåˆ—è³‡æ–™
3. **housing_prices.csv** - æˆ¿åƒ¹é æ¸¬è³‡æ–™
4. **credit_risk.csv** - ä¿¡ç”¨é¢¨éšªè©•ä¼°è³‡æ–™

## ä¸»è¦åŠŸèƒ½

### è³‡æ–™æ¢ç´¢ (EDA)
- è‡ªå‹•ç”Ÿæˆçµ±è¨ˆæ‘˜è¦
- æª¢æ¸¬ç•°å¸¸å€¼
- è¦–è¦ºåŒ–åˆ†ä½ˆ
- ç›¸é—œæ€§åˆ†æ
- ç¼ºå¤±å€¼åˆ†æ

### ç‰¹å¾µå·¥ç¨‹
- ç‰¹å¾µé¸æ“‡
- ç‰¹å¾µè½‰æ›
- ç‰¹å¾µç·¨ç¢¼ï¼ˆOne-Hot, Labelï¼‰
- ç‰¹å¾µç¸®æ”¾ï¼ˆæ¨™æº–åŒ–ã€æ­£è¦åŒ–ï¼‰
- å¤šé …å¼ç‰¹å¾µ
- äº¤äº’ç‰¹å¾µ

### æ¨¡å‹è¨“ç·´
- è‡ªå‹•è¶…åƒæ•¸èª¿æ•´
- äº¤å‰é©—è­‰
- æ¨¡å‹æ¯”è¼ƒ
- é›†æˆå­¸ç¿’
- æ¨¡å‹æŒä¹…åŒ–

### æ¨¡å‹è©•ä¼°
- åˆ†é¡æŒ‡æ¨™ï¼ˆAccuracy, Precision, Recall, F1, AUCï¼‰
- å›æ­¸æŒ‡æ¨™ï¼ˆMSE, RMSE, MAE, RÂ²ï¼‰
- æ··æ·†çŸ©é™£
- ROC æ›²ç·š
- å­¸ç¿’æ›²ç·š

## ç¯„ä¾‹æ‡‰ç”¨

### 1. å®¢æˆ¶æµå¤±é æ¸¬

```python
from predictor import Predictor

# è¨“ç·´æµå¤±é æ¸¬æ¨¡å‹
predictor = Predictor(task='classification')
predictor.train(X_train, y_train, model_type='xgboost')

# é æ¸¬æµå¤±é¢¨éšª
churn_risk = predictor.predict_proba(X_new)

# è­˜åˆ¥é«˜é¢¨éšªå®¢æˆ¶
high_risk = churn_risk[churn_risk[:, 1] > 0.7]
```

### 2. éŠ·å”®é æ¸¬

```python
from time_series import TimeSeriesAnalyzer

ts = TimeSeriesAnalyzer(sales_data, date_column='date')
forecast = ts.forecast(periods=90, method='prophet')

# è¨ˆç®—é æ¸¬å€é–“
ts.plot_forecast_with_confidence(forecast)
```

### 3. æˆ¿åƒ¹é æ¸¬

```python
from predictor import Predictor
from feature_engineering import FeatureEngineer

# ç‰¹å¾µå·¥ç¨‹
fe = FeatureEngineer(housing_data)
fe.handle_missing_values()
fe.encode_categorical(['location', 'type'])
fe.create_polynomial_features(['area', 'rooms'])

# è¨“ç·´æ¨¡å‹
predictor = Predictor(task='regression')
predictor.train(X_train, y_train, model_type='random_forest')

# è©•ä¼°
metrics = predictor.evaluate(X_test, y_test)
print(f"RÂ² Score: {metrics['r2']:.3f}")
```

## æŠ€è¡“æ£§

- **Pandas** - è³‡æ–™è™•ç†
- **NumPy** - æ•¸å€¼è¨ˆç®—
- **Scikit-learn** - æ©Ÿå™¨å­¸ç¿’
- **XGBoost / LightGBM** - Gradient Boosting
- **Statsmodels** - çµ±è¨ˆæ¨¡å‹
- **Prophet** - æ™‚é–“åºåˆ—é æ¸¬
- **Matplotlib / Seaborn** - è¦–è¦ºåŒ–
- **Plotly** - äº’å‹•å¼åœ–è¡¨
- **Streamlit** - Web UI

## æœ€ä½³å¯¦è¸

1. **è³‡æ–™æº–å‚™**
   - æ¸…ç†ç¼ºå¤±å€¼å’Œç•°å¸¸å€¼
   - é©ç•¶çš„ç‰¹å¾µç¸®æ”¾
   - è™•ç†é¡åˆ¥ä¸å¹³è¡¡

2. **æ¨¡å‹é¸æ“‡**
   - å¾ç°¡å–®æ¨¡å‹é–‹å§‹
   - ä½¿ç”¨äº¤å‰é©—è­‰
   - æ¯”è¼ƒå¤šå€‹æ¨¡å‹

3. **æ¨¡å‹è©•ä¼°**
   - ä½¿ç”¨å¤šå€‹è©•ä¼°æŒ‡æ¨™
   - æª¢æŸ¥éæ“¬åˆ
   - åˆ†æç‰¹å¾µé‡è¦æ€§

4. **éƒ¨ç½²**
   - æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶
   - ç›£æ§æ¨¡å‹æ€§èƒ½
   - å®šæœŸé‡æ–°è¨“ç·´

## æˆæ¬Š

MIT License
