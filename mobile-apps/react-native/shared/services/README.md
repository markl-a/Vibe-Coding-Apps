# AI æœåŠ¡æ–‡æ¡£ ğŸ¤–

å®Œæ•´çš„ AI é›†æˆæœåŠ¡å±‚ï¼Œæ”¯æŒå¤šä¸ªä¸»æµ AI æä¾›å•†ã€‚

## æ”¯æŒçš„ AI æä¾›å•†

- **OpenAI** (GPT-4, GPT-4o, GPT-4o-mini)
- **Anthropic Claude** (Claude 3.5 Sonnet, Claude 3 Opus/Haiku)
- **Google Gemini** (Gemini 2.0 Flash, Gemini 1.5 Pro)
- **Ollama** (æœ¬åœ°è¿è¡Œçš„å¼€æºæ¨¡å‹)

## å®‰è£…

### ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GEMINI_API_KEY=AIza...
```

### ä¾èµ–å®‰è£…

```bash
npm install
# æˆ–
yarn install
```

## åŸºç¡€ç”¨æ³•

### ç®€å•å¯¹è¯

```typescript
import { chat } from '../shared/services/aiService';

const messages = [
  {
    role: 'user',
    content: 'ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ React Native',
  },
];

const config = {
  provider: 'openai',
  apiKey: process.env.OPENAI_API_KEY,
  model: 'gpt-4o-mini',
};

const response = await chat(messages, config);
console.log(response.message);
```

### å¤šè½®å¯¹è¯

```typescript
import { chat, Message } from '../shared/services/aiService';

const conversationHistory: Message[] = [
  {
    role: 'system',
    content: 'ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„ AI åŠ©æ‰‹ã€‚',
  },
  {
    role: 'user',
    content: 'ä»€ä¹ˆæ˜¯ React Nativeï¼Ÿ',
  },
  {
    role: 'assistant',
    content: 'React Native æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºè·¨å¹³å°ç§»åŠ¨åº”ç”¨çš„æ¡†æ¶...',
  },
  {
    role: 'user',
    content: 'å®ƒå’Œ Flutter æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ',
  },
];

const response = await chat(conversationHistory, config);
```

### ä½¿ç”¨ä¸åŒçš„ AI æä¾›å•†

```typescript
// OpenAI
const openaiConfig = {
  provider: 'openai',
  apiKey: process.env.OPENAI_API_KEY,
  model: 'gpt-4o-mini',
};

// Anthropic Claude
const claudeConfig = {
  provider: 'anthropic',
  apiKey: process.env.ANTHROPIC_API_KEY,
  model: 'claude-3-5-sonnet-20241022',
};

// Google Gemini
const geminiConfig = {
  provider: 'gemini',
  apiKey: process.env.GEMINI_API_KEY,
  model: 'gemini-2.0-flash-exp',
};

// Ollama (æœ¬åœ°)
const ollamaConfig = {
  provider: 'ollama',
  model: 'llama3.2',
  baseURL: 'http://localhost:11434',
};
```

### æµå¼å“åº”

```typescript
import { chatStream } from '../shared/services/aiService';

const stream = chatStream(messages, config);

for await (const chunk of stream) {
  process.stdout.write(chunk);
}
```

## é¢„è®¾ AI åŠ©æ‰‹

ä½¿ç”¨é¢„é…ç½®çš„ AI åŠ©æ‰‹è§’è‰²ï¼š

```typescript
import { AI_ASSISTANTS } from '../shared/services/aiService';

// å¯ç”¨çš„åŠ©æ‰‹ç±»å‹
const assistants = {
  general: 'é€šç”¨åŠ©æ‰‹',
  coder: 'ç¼–ç¨‹åŠ©æ‰‹',
  translator: 'ç¿»è¯‘åŠ©æ‰‹',
  writer: 'å†™ä½œåŠ©æ‰‹',
  teacher: 'æ•™å­¦åŠ©æ‰‹',
};

// ä½¿ç”¨é¢„è®¾åŠ©æ‰‹
const messages = [
  {
    role: 'system',
    content: AI_ASSISTANTS.coder.systemPrompt,
  },
  {
    role: 'user',
    content: 'å¦‚ä½•åœ¨ React Native ä¸­å®ç°é˜²æŠ–ï¼Ÿ',
  },
];
```

## å®é™…åº”ç”¨ç¤ºä¾‹

### 1. èŠå¤©åº”ç”¨

```typescript
import React, { useState } from 'react';
import { View, TextInput, Button, Text } from 'react-native';
import { chat, Message, AIConfig } from '../shared/services/aiService';

function ChatApp() {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);

  const config: AIConfig = {
    provider: 'openai',
    apiKey: process.env.OPENAI_API_KEY,
  };

  const sendMessage = async () => {
    if (!input.trim()) return;

    const userMessage: Message = {
      role: 'user',
      content: input,
    };

    setMessages([...messages, userMessage]);
    setInput('');
    setLoading(true);

    try {
      const response = await chat([...messages, userMessage], config);

      const aiMessage: Message = {
        role: 'assistant',
        content: response.message,
      };

      setMessages([...messages, userMessage, aiMessage]);
    } catch (error) {
      console.error(error);
    } finally {
      setLoading(false);
    }
  };

  return (
    <View>
      {messages.map((msg, i) => (
        <Text key={i}>
          {msg.role}: {msg.content}
        </Text>
      ))}
      <TextInput value={input} onChangeText={setInput} />
      <Button title="å‘é€" onPress={sendMessage} disabled={loading} />
    </View>
  );
}
```

### 2. æ–‡æœ¬æ‘˜è¦

```typescript
async function summarizeText(text: string): Promise<string> {
  const messages: Message[] = [
    {
      role: 'system',
      content: 'è¯·ä¸ºä»¥ä¸‹æ–‡æœ¬ç”Ÿæˆç®€æ´çš„æ‘˜è¦ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚',
    },
    {
      role: 'user',
      content: text,
    },
  ];

  const config: AIConfig = {
    provider: 'openai',
    apiKey: process.env.OPENAI_API_KEY,
    model: 'gpt-4o-mini',
  };

  const response = await chat(messages, config);
  return response.message;
}

// ä½¿ç”¨
const summary = await summarizeText('å¾ˆé•¿çš„æ–‡æœ¬å†…å®¹...');
```

### 3. ä»£ç è§£é‡Š

```typescript
async function explainCode(code: string, language: string): Promise<string> {
  const messages: Message[] = [
    {
      role: 'system',
      content: 'ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹æ•™å­¦åŠ©æ‰‹ã€‚è¯·è¯¦ç»†è§£é‡Šä»£ç çš„åŠŸèƒ½å’Œå·¥ä½œåŸç†ã€‚',
    },
    {
      role: 'user',
      content: `è¯·è§£é‡Šä»¥ä¸‹ ${language} ä»£ç ï¼š\n\n${code}`,
    },
  ];

  const config: AIConfig = {
    provider: 'anthropic',
    apiKey: process.env.ANTHROPIC_API_KEY,
    model: 'claude-3-5-sonnet-20241022',
  };

  const response = await chat(messages, config);
  return response.message;
}
```

### 4. è¯­è¨€ç¿»è¯‘

```typescript
async function translate(
  text: string,
  targetLanguage: string
): Promise<string> {
  const messages: Message[] = [
    {
      role: 'system',
      content: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†æ–‡æœ¬ç¿»è¯‘æˆ${targetLanguage}ï¼Œä¿æŒåŸæ„å’Œè¯­æ°”ã€‚`,
    },
    {
      role: 'user',
      content: text,
    },
  ];

  const config: AIConfig = {
    provider: 'gemini',
    apiKey: process.env.GEMINI_API_KEY,
  };

  const response = await chat(messages, config);
  return response.message;
}

// ä½¿ç”¨
const translation = await translate('Hello, how are you?', 'ä¸­æ–‡');
```

### 5. å›¾åƒæè¿°ç”Ÿæˆï¼ˆä½¿ç”¨ GPT-4 Visionï¼‰

```typescript
async function describeImage(imageUrl: string): Promise<string> {
  // æ³¨æ„ï¼šéœ€è¦ä½¿ç”¨æ”¯æŒè§†è§‰çš„æ¨¡å‹
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
    },
    body: JSON.stringify({
      model: 'gpt-4o',
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: 'è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚',
            },
            {
              type: 'image_url',
              image_url: {
                url: imageUrl,
              },
            },
          ],
        },
      ],
    }),
  });

  const data = await response.json();
  return data.choices[0].message.content;
}
```

## API å‚è€ƒ

### chat()

ä¸»è¦çš„èŠå¤©å®Œæˆå‡½æ•°ã€‚

```typescript
async function chat(
  messages: Message[],
  config: AIConfig
): Promise<ChatCompletionResponse>
```

**å‚æ•°:**
- `messages`: æ¶ˆæ¯å†å²æ•°ç»„
- `config`: AI é…ç½®å¯¹è±¡

**è¿”å›:**
```typescript
{
  message: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}
```

### chatStream()

æµå¼å“åº”å‡½æ•°ï¼ˆä»…éƒ¨åˆ†æä¾›å•†æ”¯æŒï¼‰ã€‚

```typescript
async function* chatStream(
  messages: Message[],
  config: AIConfig
): AsyncGenerator<string>
```

### ç±»å‹å®šä¹‰

```typescript
interface Message {
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp?: Date;
}

interface AIConfig {
  provider: 'openai' | 'anthropic' | 'gemini' | 'ollama';
  apiKey?: string;
  model?: string;
  baseURL?: string;
}
```

## é”™è¯¯å¤„ç†

```typescript
try {
  const response = await chat(messages, config);
  console.log(response.message);
} catch (error) {
  if (error instanceof Error) {
    console.error('AI é”™è¯¯:', error.message);

    // å¤„ç†ç‰¹å®šé”™è¯¯
    if (error.message.includes('API key')) {
      console.error('API å¯†é’¥æ— æ•ˆ');
    } else if (error.message.includes('quota')) {
      console.error('API é…é¢å·²ç”¨å®Œ');
    } else if (error.message.includes('network')) {
      console.error('ç½‘ç»œè¿æ¥é”™è¯¯');
    }
  }
}
```

## æœ€ä½³å®è·µ

1. **API å¯†é’¥å®‰å…¨**
   - ä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç  API å¯†é’¥
   - ä½¿ç”¨ç¯å¢ƒå˜é‡
   - åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨åç«¯ä»£ç†

2. **æˆæœ¬æ§åˆ¶**
   - é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼ˆmini ç‰ˆæœ¬é€šå¸¸æ›´ä¾¿å®œï¼‰
   - é™åˆ¶ token æ•°é‡
   - å®ç°è¯·æ±‚ç¼“å­˜

3. **ç”¨æˆ·ä½“éªŒ**
   - æ˜¾ç¤ºåŠ è½½çŠ¶æ€
   - å®ç°æµå¼å“åº”æå‡ä½“éªŒ
   - ä¼˜é›…å¤„ç†é”™è¯¯

4. **æ€§èƒ½ä¼˜åŒ–**
   - ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹å¤„ç†ç®€å•ä»»åŠ¡
   - æ‰¹é‡å¤„ç†è¯·æ±‚
   - å®ç°æœ¬åœ°ç¼“å­˜

5. **æç¤ºå·¥ç¨‹**
   - ç¼–å†™æ¸…æ™°çš„ system prompt
   - æä¾›å……è¶³çš„ä¸Šä¸‹æ–‡
   - ä½¿ç”¨ç¤ºä¾‹æŒ‡å¯¼è¾“å‡ºæ ¼å¼

## Token ä½¿ç”¨ä¼°ç®—

ä¸åŒæ¨¡å‹çš„å®šä»·ï¼ˆä»…ä¾›å‚è€ƒï¼‰ï¼š

| æ¨¡å‹ | è¾“å…¥ Token | è¾“å‡º Token |
|------|-----------|-----------|
| GPT-4o-mini | $0.15 / 1M | $0.60 / 1M |
| GPT-4o | $2.50 / 1M | $10.00 / 1M |
| Claude 3.5 Sonnet | $3.00 / 1M | $15.00 / 1M |
| Gemini 2.0 Flash | å…è´¹(æœ‰é™) | å…è´¹(æœ‰é™) |

1000 ä¸ª token â‰ˆ 750 ä¸ªè‹±æ–‡å•è¯ â‰ˆ 500 ä¸ªä¸­æ–‡å­—ç¬¦

## æ•…éšœæ’æŸ¥

### API å¯†é’¥é”™è¯¯
```
Error: OpenAI API è°ƒç”¨å¤±è´¥
```
æ£€æŸ¥ API å¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®ã€‚

### ç½‘ç»œé”™è¯¯
```
Error: Failed to fetch
```
æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ API ç«¯ç‚¹æ˜¯å¦å¯è®¿é—®ã€‚

### é…é¢è¶…é™
```
Error: You exceeded your current quota
```
æ£€æŸ¥ API è´¦æˆ·ä½™é¢å’Œä½¿ç”¨é™åˆ¶ã€‚

## æœ¬åœ°å¼€å‘ï¼ˆOllamaï¼‰

ä½¿ç”¨ Ollama åœ¨æœ¬åœ°è¿è¡Œæ¨¡å‹ï¼š

```bash
# å®‰è£… Ollama
# è®¿é—® https://ollama.ai

# ä¸‹è½½æ¨¡å‹
ollama pull llama3.2

# å¯åŠ¨æœåŠ¡ï¼ˆé»˜è®¤ç«¯å£ 11434ï¼‰
ollama serve
```

åœ¨ä»£ç ä¸­ä½¿ç”¨ï¼š

```typescript
const config: AIConfig = {
  provider: 'ollama',
  model: 'llama3.2',
  baseURL: 'http://localhost:11434',
};
```

## è®¸å¯è¯

MIT License
