#!/usr/bin/env python3
"""
JSON Transformer - JSON è³‡æ–™è½‰æ›å’Œè™•ç†å·¥å…·

åŠŸèƒ½ï¼š
- JSON æ ¼å¼åŒ–èˆ‡ç¾åŒ–
- JSONPath æŸ¥è©¢èˆ‡æå–
- Schema é©—è­‰
- è³‡æ–™è½‰æ›ï¼ˆCSVã€YAMLã€XMLï¼‰
- æ‰¹æ¬¡è™•ç†
- æ·±åº¦åˆä½µ
"""

import json
import argparse
import sys
import csv
from pathlib import Path
from typing import Any, Dict, List, Union
from jsonpath_ng import parse
from jsonschema import validate, ValidationError
import yaml

def load_json(file_path: str) -> Any:
    """è¼‰å…¥ JSON æª”æ¡ˆ"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        print(f"âŒ JSON æ ¼å¼éŒ¯èª¤: {e}")
        sys.exit(1)
    except FileNotFoundError:
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
        sys.exit(1)

def save_json(data: Any, file_path: str, prettify: bool = True):
    """å„²å­˜ JSON æª”æ¡ˆ"""
    with open(file_path, 'w', encoding='utf-8') as f:
        if prettify:
            json.dump(data, f, ensure_ascii=False, indent=2)
        else:
            json.dump(data, f, ensure_ascii=False)
    print(f"âœ… å·²å„²å­˜: {file_path}")

def prettify_json(data: Any) -> str:
    """ç¾åŒ– JSON æ ¼å¼"""
    return json.dumps(data, ensure_ascii=False, indent=2)

def minify_json(data: Any) -> str:
    """å£“ç¸® JSON æ ¼å¼"""
    return json.dumps(data, ensure_ascii=False, separators=(',', ':'))

def query_jsonpath(data: Any, path: str) -> List[Any]:
    """ä½¿ç”¨ JSONPath æŸ¥è©¢è³‡æ–™"""
    try:
        jsonpath_expr = parse(path)
        matches = jsonpath_expr.find(data)
        return [match.value for match in matches]
    except Exception as e:
        print(f"âŒ JSONPath æŸ¥è©¢éŒ¯èª¤: {e}")
        return []

def validate_schema(data: Any, schema_file: str) -> bool:
    """é©—è­‰ JSON Schema"""
    try:
        schema = load_json(schema_file)
        validate(instance=data, schema=schema)
        print("âœ… Schema é©—è­‰é€šé")
        return True
    except ValidationError as e:
        print(f"âŒ Schema é©—è­‰å¤±æ•—: {e.message}")
        return False
    except Exception as e:
        print(f"âŒ é©—è­‰éŒ¯èª¤: {e}")
        return False

def json_to_csv(data: Any, output_file: str):
    """å°‡ JSON è½‰æ›ç‚º CSV"""
    # è™•ç†åˆ—è¡¨æ ¼å¼çš„ JSON
    if isinstance(data, list):
        if not data:
            print("âŒ ç©ºçš„ JSON é™£åˆ—")
            return

        # å–å¾—æ‰€æœ‰æ¬„ä½
        fieldnames = set()
        for item in data:
            if isinstance(item, dict):
                fieldnames.update(item.keys())

        fieldnames = sorted(fieldnames)

        with open(output_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for item in data:
                if isinstance(item, dict):
                    writer.writerow(item)

        print(f"âœ… å·²è½‰æ›ç‚º CSV: {output_file}")
    else:
        print("âŒ JSON å¿…é ˆæ˜¯é™£åˆ—æ ¼å¼æ‰èƒ½è½‰æ›ç‚º CSV")

def json_to_yaml(data: Any, output_file: str):
    """å°‡ JSON è½‰æ›ç‚º YAML"""
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            yaml.dump(data, f, default_flow_style=False, allow_unicode=True)
        print(f"âœ… å·²è½‰æ›ç‚º YAML: {output_file}")
    except Exception as e:
        print(f"âŒ è½‰æ›å¤±æ•—: {e}")

def deep_merge(dict1: Dict, dict2: Dict) -> Dict:
    """æ·±åº¦åˆä½µå…©å€‹å­—å…¸"""
    result = dict1.copy()
    for key, value in dict2.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = deep_merge(result[key], value)
        else:
            result[key] = value
    return result

def merge_json_files(files: List[str], merge_type: str = 'shallow') -> Any:
    """åˆä½µå¤šå€‹ JSON æª”æ¡ˆ"""
    if not files:
        return {}

    result = load_json(files[0])

    for file_path in files[1:]:
        data = load_json(file_path)

        if merge_type == 'deep' and isinstance(result, dict) and isinstance(data, dict):
            result = deep_merge(result, data)
        elif isinstance(result, list) and isinstance(data, list):
            result.extend(data)
        elif isinstance(result, dict) and isinstance(data, dict):
            result.update(data)
        else:
            print(f"âš ï¸  ç„¡æ³•åˆä½µä¸åŒé¡å‹çš„è³‡æ–™")

    return result

def extract_fields(data: Any, fields: List[str]) -> Any:
    """æå–æŒ‡å®šæ¬„ä½"""
    if isinstance(data, list):
        return [
            {field: item.get(field) for field in fields if field in item}
            for item in data
            if isinstance(item, dict)
        ]
    elif isinstance(data, dict):
        return {field: data.get(field) for field in fields if field in data}
    return data

def flatten_json(data: Dict, parent_key: str = '', sep: str = '.') -> Dict:
    """å±•å¹³å·¢ç‹€ JSON"""
    items = []
    for k, v in data.items():
        new_key = f"{parent_key}{sep}{k}" if parent_key else k
        if isinstance(v, dict):
            items.extend(flatten_json(v, new_key, sep=sep).items())
        else:
            items.append((new_key, v))
    return dict(items)

def main():
    parser = argparse.ArgumentParser(
        description='JSON Transformer - JSON è³‡æ–™è½‰æ›å’Œè™•ç†å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument('files', nargs='+', help='JSON æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--prettify', action='store_true', help='ç¾åŒ– JSON æ ¼å¼')
    parser.add_argument('--minify', action='store_true', help='å£“ç¸® JSON æ ¼å¼')
    parser.add_argument('--query', type=str, help='JSONPath æŸ¥è©¢è¡¨é”å¼')
    parser.add_argument('--validate', type=str, metavar='SCHEMA', help='é©—è­‰ JSON Schema')
    parser.add_argument('--to-csv', type=str, metavar='OUTPUT', help='è½‰æ›ç‚º CSV')
    parser.add_argument('--to-yaml', type=str, metavar='OUTPUT', help='è½‰æ›ç‚º YAML')
    parser.add_argument('--merge', choices=['shallow', 'deep'], help='åˆä½µå¤šå€‹ JSON æª”æ¡ˆ')
    parser.add_argument('--extract', type=str, help='æå–æŒ‡å®šæ¬„ä½ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰')
    parser.add_argument('--flatten', action='store_true', help='å±•å¹³å·¢ç‹€ JSON')
    parser.add_argument('-o', '--output', type=str, help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘')

    args = parser.parse_args()

    # è¼‰å…¥ç¬¬ä¸€å€‹ JSON æª”æ¡ˆ
    data = load_json(args.files[0])

    # åˆä½µå¤šå€‹æª”æ¡ˆ
    if args.merge:
        print(f"ğŸ”„ åˆä½µ {len(args.files)} å€‹æª”æ¡ˆ...")
        data = merge_json_files(args.files, args.merge)

    # JSONPath æŸ¥è©¢
    if args.query:
        print(f"ğŸ” æŸ¥è©¢: {args.query}")
        results = query_jsonpath(data, args.query)
        print(f"æ‰¾åˆ° {len(results)} å€‹çµæœ:")
        print(prettify_json(results))
        return

    # Schema é©—è­‰
    if args.validate:
        validate_schema(data, args.validate)
        return

    # æå–æ¬„ä½
    if args.extract:
        fields = [f.strip() for f in args.extract.split(',')]
        print(f"ğŸ“‹ æå–æ¬„ä½: {', '.join(fields)}")
        data = extract_fields(data, fields)

    # å±•å¹³ JSON
    if args.flatten:
        if isinstance(data, dict):
            print("ğŸ”§ å±•å¹³å·¢ç‹€ JSON...")
            data = flatten_json(data)
        else:
            print("âš ï¸  åªèƒ½å±•å¹³å­—å…¸é¡å‹çš„ JSON")

    # è½‰æ›ç‚º CSV
    if args.to_csv:
        json_to_csv(data, args.to_csv)
        return

    # è½‰æ›ç‚º YAML
    if args.to_yaml:
        json_to_yaml(data, args.to_yaml)
        return

    # ç¾åŒ–æˆ–å£“ç¸®
    if args.prettify:
        output = prettify_json(data)
        print(output)
        if args.output:
            save_json(data, args.output, prettify=True)
    elif args.minify:
        output = minify_json(data)
        print(output)
        if args.output:
            save_json(data, args.output, prettify=False)
    elif args.output:
        save_json(data, args.output)
    else:
        print(prettify_json(data))

if __name__ == '__main__':
    main()
