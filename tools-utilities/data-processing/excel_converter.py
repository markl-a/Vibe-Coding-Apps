#!/usr/bin/env python3
"""
Excel Converter - Excel æª”æ¡ˆè™•ç†å’Œè½‰æ›å·¥å…·

åŠŸèƒ½ï¼š
- Excel è®€å–èˆ‡å¯«å…¥
- å·¥ä½œè¡¨æ“ä½œ
- è½‰æ›ç‚º CSV/JSON
- æ‰¹æ¬¡è™•ç†å¤šå€‹å·¥ä½œç°¿
- è³‡æ–™é©—è­‰
- æ ¼å¼ä¿ç•™
"""

import argparse
import sys
import json
from pathlib import Path
from typing import List, Dict, Any, Union
import pandas as pd
import openpyxl
from openpyxl import load_workbook

def load_excel(file_path: str, sheet_name: Union[str, int] = 0) -> pd.DataFrame:
    """è¼‰å…¥ Excel æª”æ¡ˆ"""
    try:
        return pd.read_excel(file_path, sheet_name=sheet_name)
    except FileNotFoundError:
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ è®€å–éŒ¯èª¤: {e}")
        sys.exit(1)

def get_sheet_names(file_path: str) -> List[str]:
    """å–å¾—æ‰€æœ‰å·¥ä½œè¡¨åç¨±"""
    try:
        xl_file = pd.ExcelFile(file_path)
        return xl_file.sheet_names
    except Exception as e:
        print(f"âŒ è®€å–å·¥ä½œè¡¨å¤±æ•—: {e}")
        return []

def excel_info(file_path: str):
    """é¡¯ç¤º Excel æª”æ¡ˆè³‡è¨Š"""
    print(f"ğŸ“Š æª”æ¡ˆè³‡è¨Š: {file_path}\n")

    sheets = get_sheet_names(file_path)
    print(f"ğŸ“‹ å·¥ä½œè¡¨æ•¸é‡: {len(sheets)}")

    for i, sheet in enumerate(sheets, 1):
        print(f"\n{i}. {sheet}")
        try:
            df = load_excel(file_path, sheet)
            print(f"   è³‡æ–™ç­†æ•¸: {len(df)}")
            print(f"   æ¬„ä½æ•¸: {len(df.columns)}")
            print(f"   æ¬„ä½åç¨±: {', '.join(df.columns[:5])}", end='')
            if len(df.columns) > 5:
                print(f" ... ({len(df.columns) - 5} å€‹æ¬„ä½æœªé¡¯ç¤º)")
            else:
                print()
        except Exception as e:
            print(f"   âŒ è®€å–å¤±æ•—: {e}")

def excel_to_csv(file_path: str, output_file: str, sheet_name: Union[str, int] = 0):
    """å°‡ Excel è½‰æ›ç‚º CSV"""
    df = load_excel(file_path, sheet_name)
    df.to_csv(output_file, index=False, encoding='utf-8')
    print(f"âœ… å·²è½‰æ›ç‚º CSV: {output_file}")
    print(f"   è³‡æ–™ç­†æ•¸: {len(df)}, æ¬„ä½æ•¸: {len(df.columns)}")

def excel_to_json(file_path: str, output_file: str, sheet_name: Union[str, int] = 0, orient: str = 'records'):
    """å°‡ Excel è½‰æ›ç‚º JSON"""
    df = load_excel(file_path, sheet_name)
    df.to_json(output_file, orient=orient, force_ascii=False, indent=2)
    print(f"âœ… å·²è½‰æ›ç‚º JSON: {output_file}")
    print(f"   è³‡æ–™ç­†æ•¸: {len(df)}, æ¬„ä½æ•¸: {len(df.columns)}")

def merge_sheets(file_path: str, output_file: str, output_format: str = 'csv'):
    """åˆä½µæ‰€æœ‰å·¥ä½œè¡¨"""
    sheets = get_sheet_names(file_path)

    if not sheets:
        print("âŒ æ²’æœ‰å·¥ä½œè¡¨å¯åˆä½µ")
        return

    print(f"ğŸ”„ åˆä½µ {len(sheets)} å€‹å·¥ä½œè¡¨...")

    all_data = []
    for sheet in sheets:
        try:
            df = load_excel(file_path, sheet)
            df['ä¾†æºå·¥ä½œè¡¨'] = sheet
            all_data.append(df)
            print(f"  âœ… {sheet}: {len(df)} ç­†")
        except Exception as e:
            print(f"  âŒ {sheet}: è®€å–å¤±æ•— - {e}")

    if not all_data:
        print("âŒ æ²’æœ‰è³‡æ–™å¯åˆä½µ")
        return

    merged_df = pd.concat(all_data, ignore_index=True)
    print(f"\nâœ… åˆä½µå®Œæˆï¼Œå…± {len(merged_df)} ç­†è³‡æ–™")

    if output_format == 'csv':
        merged_df.to_csv(output_file, index=False, encoding='utf-8')
    elif output_format == 'json':
        merged_df.to_json(output_file, orient='records', force_ascii=False, indent=2)
    elif output_format == 'excel':
        merged_df.to_excel(output_file, index=False)

    print(f"âœ… å·²å„²å­˜: {output_file}")

def split_sheets(file_path: str, output_dir: str, output_format: str = 'csv'):
    """å°‡æ¯å€‹å·¥ä½œè¡¨åˆ†åˆ¥å„²å­˜"""
    sheets = get_sheet_names(file_path)

    if not sheets:
        print("âŒ æ²’æœ‰å·¥ä½œè¡¨")
        return

    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ“‚ å°‡ {len(sheets)} å€‹å·¥ä½œè¡¨åˆ†åˆ¥å„²å­˜åˆ°: {output_dir}")

    for sheet in sheets:
        try:
            df = load_excel(file_path, sheet)

            # æ¸…ç†æª”åï¼ˆç§»é™¤ç‰¹æ®Šå­—å…ƒï¼‰
            safe_name = "".join(c for c in sheet if c.isalnum() or c in (' ', '-', '_')).strip()

            if output_format == 'csv':
                output_file = output_path / f"{safe_name}.csv"
                df.to_csv(output_file, index=False, encoding='utf-8')
            elif output_format == 'json':
                output_file = output_path / f"{safe_name}.json"
                df.to_json(output_file, orient='records', force_ascii=False, indent=2)
            elif output_format == 'excel':
                output_file = output_path / f"{safe_name}.xlsx"
                df.to_excel(output_file, index=False)

            print(f"  âœ… {sheet} -> {output_file.name} ({len(df)} ç­†)")
        except Exception as e:
            print(f"  âŒ {sheet}: å¤±æ•— - {e}")

def batch_convert(pattern: str, output_dir: str, output_format: str = 'csv'):
    """æ‰¹æ¬¡è½‰æ›å¤šå€‹ Excel æª”æ¡ˆ"""
    from glob import glob

    files = glob(pattern)

    if not files:
        print(f"âŒ æ‰¾ä¸åˆ°ç¬¦åˆçš„æª”æ¡ˆ: {pattern}")
        return

    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ”„ æ‰¹æ¬¡è½‰æ› {len(files)} å€‹æª”æ¡ˆ...")

    for file_path in files:
        try:
            file_name = Path(file_path).stem

            if output_format == 'csv':
                output_file = output_path / f"{file_name}.csv"
                excel_to_csv(file_path, str(output_file))
            elif output_format == 'json':
                output_file = output_path / f"{file_name}.json"
                excel_to_json(file_path, str(output_file))

            print(f"  âœ… {file_name}")
        except Exception as e:
            print(f"  âŒ {file_name}: {e}")

def add_sheet(file_path: str, sheet_name: str, data_file: str):
    """æ–°å¢å·¥ä½œè¡¨"""
    try:
        # è¼‰å…¥è³‡æ–™
        if data_file.endswith('.csv'):
            df = pd.read_csv(data_file)
        elif data_file.endswith('.json'):
            df = pd.read_json(data_file)
        else:
            print(f"âŒ ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼: {data_file}")
            return

        # è¼‰å…¥æˆ–å‰µå»ºå·¥ä½œç°¿
        try:
            with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:
                df.to_excel(writer, sheet_name=sheet_name, index=False)
        except FileNotFoundError:
            with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name=sheet_name, index=False)

        print(f"âœ… å·²æ–°å¢å·¥ä½œè¡¨: {sheet_name}")
        print(f"   è³‡æ–™ç­†æ•¸: {len(df)}, æ¬„ä½æ•¸: {len(df.columns)}")
    except Exception as e:
        print(f"âŒ æ–°å¢å·¥ä½œè¡¨å¤±æ•—: {e}")

def remove_sheet(file_path: str, sheet_name: str):
    """ç§»é™¤å·¥ä½œè¡¨"""
    try:
        wb = load_workbook(file_path)

        if sheet_name not in wb.sheetnames:
            print(f"âŒ å·¥ä½œè¡¨ä¸å­˜åœ¨: {sheet_name}")
            return

        wb.remove(wb[sheet_name])
        wb.save(file_path)
        print(f"âœ… å·²ç§»é™¤å·¥ä½œè¡¨: {sheet_name}")
    except Exception as e:
        print(f"âŒ ç§»é™¤å·¥ä½œè¡¨å¤±æ•—: {e}")

def main():
    parser = argparse.ArgumentParser(
        description='Excel Converter - Excel æª”æ¡ˆè™•ç†å’Œè½‰æ›å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument('input', nargs='?', help='è¼¸å…¥ Excel æª”æ¡ˆ')
    parser.add_argument('--info', action='store_true', help='é¡¯ç¤º Excel æª”æ¡ˆè³‡è¨Š')
    parser.add_argument('--sheet', type=str, default='0', help='æŒ‡å®šå·¥ä½œè¡¨ï¼ˆåç¨±æˆ–ç´¢å¼•ï¼‰')
    parser.add_argument('--to-csv', type=str, metavar='OUTPUT', help='è½‰æ›ç‚º CSV')
    parser.add_argument('--to-json', type=str, metavar='OUTPUT', help='è½‰æ›ç‚º JSON')
    parser.add_argument('--merge-sheets', action='store_true', help='åˆä½µæ‰€æœ‰å·¥ä½œè¡¨')
    parser.add_argument('--split-sheets', type=str, metavar='DIR', help='å°‡å·¥ä½œè¡¨åˆ†åˆ¥å„²å­˜')
    parser.add_argument('--batch', type=str, metavar='PATTERN', help='æ‰¹æ¬¡è½‰æ›ï¼ˆä¾‹å¦‚: *.xlsxï¼‰')
    parser.add_argument('--add-sheet', type=str, metavar='NAME', help='æ–°å¢å·¥ä½œè¡¨')
    parser.add_argument('--data-file', type=str, help='è³‡æ–™æª”æ¡ˆï¼ˆç”¨æ–¼æ–°å¢å·¥ä½œè¡¨ï¼‰')
    parser.add_argument('--remove-sheet', type=str, metavar='NAME', help='ç§»é™¤å·¥ä½œè¡¨')
    parser.add_argument('--format', choices=['csv', 'json', 'excel'], default='csv', help='è¼¸å‡ºæ ¼å¼')
    parser.add_argument('-o', '--output', type=str, help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘')

    args = parser.parse_args()

    # æ‰¹æ¬¡è½‰æ›
    if args.batch:
        output_dir = args.output or 'converted'
        batch_convert(args.batch, output_dir, args.format)
        return

    # æª¢æŸ¥è¼¸å…¥æª”æ¡ˆ
    if not args.input:
        parser.print_help()
        return

    # æ–°å¢å·¥ä½œè¡¨
    if args.add_sheet:
        if not args.data_file:
            print("âŒ è«‹æŒ‡å®šè³‡æ–™æª”æ¡ˆ --data-file")
            return
        add_sheet(args.input, args.add_sheet, args.data_file)
        return

    # ç§»é™¤å·¥ä½œè¡¨
    if args.remove_sheet:
        remove_sheet(args.input, args.remove_sheet)
        return

    # é¡¯ç¤ºè³‡è¨Š
    if args.info:
        excel_info(args.input)
        return

    # åˆä½µå·¥ä½œè¡¨
    if args.merge_sheets:
        output = args.output or f"{Path(args.input).stem}_merged.{args.format}"
        merge_sheets(args.input, output, args.format)
        return

    # åˆ†å‰²å·¥ä½œè¡¨
    if args.split_sheets:
        split_sheets(args.input, args.split_sheets, args.format)
        return

    # è™•ç†å·¥ä½œè¡¨åƒæ•¸
    try:
        sheet = int(args.sheet)
    except ValueError:
        sheet = args.sheet

    # è½‰æ›ç‚º CSV
    if args.to_csv:
        excel_to_csv(args.input, args.to_csv, sheet)
        return

    # è½‰æ›ç‚º JSON
    if args.to_json:
        excel_to_json(args.input, args.to_json, sheet)
        return

    # é è¨­é¡¯ç¤ºè³‡è¨Š
    excel_info(args.input)

if __name__ == '__main__':
    main()
