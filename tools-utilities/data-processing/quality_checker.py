#!/usr/bin/env python3
"""
Quality Checker - æ™ºèƒ½è³‡æ–™å“è³ªæª¢æ¸¬å™¨

åŠŸèƒ½:
- å…¨é¢çš„è³‡æ–™å“è³ªè©•ä¼°
- AI é©…å‹•çš„å“è³ªè©•åˆ†
- è³‡æ–™å®Œæ•´æ€§æª¢æŸ¥
- ä¸€è‡´æ€§é©—è­‰
- æº–ç¢ºæ€§è©•ä¼°
- åŠæ™‚æ€§æª¢æŸ¥
- æ™ºèƒ½ä¿®å¾©å»ºè­°
- è©³ç´°å“è³ªå ±å‘Š
"""

import argparse
import sys
import json
from pathlib import Path
from typing import Dict, Any, List, Tuple
from datetime import datetime
import pandas as pd
import numpy as np
from email_validator import validate_email, EmailNotValidError
import re
import warnings
warnings.filterwarnings('ignore')


class QualityChecker:
    """è³‡æ–™å“è³ªæª¢æ¸¬å™¨"""

    def __init__(self, file_path: str):
        self.file_path = Path(file_path)
        self.df = None
        self.quality_report = {
            'file_info': {},
            'completeness': {},
            'consistency': {},
            'accuracy': {},
            'validity': {},
            'uniqueness': {},
            'overall_score': 0,
            'issues': [],
            'recommendations': []
        }
        self._load_data()

    def _load_data(self):
        """è¼‰å…¥è³‡æ–™"""
        try:
            file_ext = self.file_path.suffix.lower()

            if file_ext == '.csv':
                self.df = pd.read_csv(self.file_path)
            elif file_ext == '.json':
                self.df = pd.read_json(self.file_path)
            elif file_ext in ['.xlsx', '.xls']:
                self.df = pd.read_excel(self.file_path)
            else:
                raise ValueError(f"ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼: {file_ext}")

            self.quality_report['file_info'] = {
                'filename': self.file_path.name,
                'size_bytes': self.file_path.stat().st_size,
                'total_rows': len(self.df),
                'total_columns': len(self.df.columns),
                'columns': list(self.df.columns)
            }

            print(f"âœ… æˆåŠŸè¼‰å…¥è³‡æ–™: {len(self.df)} ç­†, {len(self.df.columns)} æ¬„")
        except Exception as e:
            print(f"âŒ è¼‰å…¥è³‡æ–™å¤±æ•—: {e}")
            sys.exit(1)

    def check_completeness(self) -> Dict[str, Any]:
        """æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§"""
        print("\nğŸ” æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§...")

        total_cells = self.df.shape[0] * self.df.shape[1]
        missing_cells = self.df.isnull().sum().sum()
        completeness_rate = (1 - missing_cells / total_cells) * 100

        column_completeness = {}
        for col in self.df.columns:
            missing_count = self.df[col].isnull().sum()
            completeness = (1 - missing_count / len(self.df)) * 100

            column_completeness[col] = {
                'missing_count': int(missing_count),
                'completeness_rate': float(completeness),
                'status': self._get_completeness_status(completeness)
            }

        self.quality_report['completeness'] = {
            'overall_completeness_rate': float(completeness_rate),
            'total_missing_cells': int(missing_cells),
            'column_completeness': column_completeness
        }

        # æ·»åŠ å•é¡Œå’Œå»ºè­°
        if completeness_rate < 95:
            self.quality_report['issues'].append({
                'severity': 'high' if completeness_rate < 80 else 'medium',
                'category': 'completeness',
                'message': f'è³‡æ–™å®Œæ•´æ€§åä½ ({completeness_rate:.1f}%)',
                'affected_columns': [
                    col for col, info in column_completeness.items()
                    if info['completeness_rate'] < 95
                ]
            })

            self.quality_report['recommendations'].append({
                'category': 'completeness',
                'priority': 'high',
                'action': 'è™•ç†ç¼ºå¤±å€¼',
                'suggestions': [
                    'ä½¿ç”¨æ’å€¼æ³•å¡«å……æ•¸å€¼å‹æ¬„ä½',
                    'ä½¿ç”¨çœ¾æ•¸å¡«å……é¡åˆ¥å‹æ¬„ä½',
                    'è€ƒæ…®åˆªé™¤ç¼ºå¤±ç‡éé«˜çš„åˆ—æˆ–æ¬„ä½',
                    'æª¢æŸ¥è³‡æ–™ä¾†æºæ˜¯å¦æœ‰å•é¡Œ'
                ]
            })

        return self.quality_report['completeness']

    def _get_completeness_status(self, rate: float) -> str:
        """ç²å–å®Œæ•´æ€§ç‹€æ…‹"""
        if rate >= 95:
            return 'excellent'
        elif rate >= 80:
            return 'good'
        elif rate >= 60:
            return 'fair'
        else:
            return 'poor'

    def check_consistency(self) -> Dict[str, Any]:
        """æª¢æŸ¥è³‡æ–™ä¸€è‡´æ€§"""
        print("\nğŸ” æª¢æŸ¥è³‡æ–™ä¸€è‡´æ€§...")

        consistency_issues = []

        # 1. æª¢æŸ¥è³‡æ–™é¡å‹ä¸€è‡´æ€§
        for col in self.df.columns:
            if self.df[col].dtype == 'object':
                # æª¢æŸ¥æ˜¯å¦æ··åˆäº†ä¸åŒé¡å‹
                types_found = set()
                for value in self.df[col].dropna().head(100):
                    if isinstance(value, str):
                        if value.isdigit():
                            types_found.add('numeric_string')
                        elif value.replace('.', '', 1).isdigit():
                            types_found.add('float_string')
                        else:
                            types_found.add('text')

                if len(types_found) > 1:
                    consistency_issues.append({
                        'column': col,
                        'issue': 'mixed_data_types',
                        'description': f'æ¬„ä½åŒ…å«æ··åˆçš„è³‡æ–™é¡å‹: {types_found}'
                    })

        # 2. æª¢æŸ¥æ ¼å¼ä¸€è‡´æ€§(ä¾‹å¦‚æ—¥æœŸã€é›»è©±)
        for col in self.df.columns:
            if self.df[col].dtype == 'object':
                sample = self.df[col].dropna().astype(str).head(50)

                # æª¢æŸ¥æ—¥æœŸæ ¼å¼
                date_formats = set()
                for value in sample:
                    if self._looks_like_date(value):
                        date_formats.add(self._detect_date_format(value))

                if len(date_formats) > 1:
                    consistency_issues.append({
                        'column': col,
                        'issue': 'inconsistent_date_format',
                        'description': f'ç™¼ç¾å¤šç¨®æ—¥æœŸæ ¼å¼: {date_formats}'
                    })

        # 3. æª¢æŸ¥å¤§å°å¯«ä¸ä¸€è‡´
        for col in self.df.columns:
            if self.df[col].dtype == 'object':
                unique_values = self.df[col].dropna().unique()
                if len(unique_values) > 1:
                    lower_map = {}
                    for val in unique_values:
                        lower_val = str(val).lower()
                        if lower_val in lower_map:
                            consistency_issues.append({
                                'column': col,
                                'issue': 'case_inconsistency',
                                'description': f'ç™¼ç¾å¤§å°å¯«ä¸ä¸€è‡´: "{lower_map[lower_val]}" vs "{val}"'
                            })
                            break
                        lower_map[lower_val] = val

        self.quality_report['consistency'] = {
            'issues_found': len(consistency_issues),
            'issues': consistency_issues
        }

        if consistency_issues:
            self.quality_report['recommendations'].append({
                'category': 'consistency',
                'priority': 'medium',
                'action': 'æ¨™æº–åŒ–è³‡æ–™æ ¼å¼',
                'suggestions': [
                    'çµ±ä¸€æ—¥æœŸæ ¼å¼ç‚º ISO 8601 (YYYY-MM-DD)',
                    'æ¨™æº–åŒ–æ–‡å­—å¤§å°å¯«',
                    'è½‰æ›è³‡æ–™é¡å‹åˆ°é©ç•¶çš„æ ¼å¼',
                    'ç§»é™¤å¤šé¤˜çš„ç©ºç™½å­—å…ƒ'
                ]
            })

        return self.quality_report['consistency']

    def _looks_like_date(self, value: str) -> bool:
        """æª¢æŸ¥å­—ä¸²æ˜¯å¦åƒæ—¥æœŸ"""
        date_patterns = [
            r'\d{4}-\d{2}-\d{2}',  # YYYY-MM-DD
            r'\d{2}/\d{2}/\d{4}',  # DD/MM/YYYY
            r'\d{4}/\d{2}/\d{2}',  # YYYY/MM/DD
        ]
        return any(re.match(pattern, value) for pattern in date_patterns)

    def _detect_date_format(self, value: str) -> str:
        """åµæ¸¬æ—¥æœŸæ ¼å¼"""
        if re.match(r'\d{4}-\d{2}-\d{2}', value):
            return 'YYYY-MM-DD'
        elif re.match(r'\d{2}/\d{2}/\d{4}', value):
            return 'DD/MM/YYYY'
        elif re.match(r'\d{4}/\d{2}/\d{2}', value):
            return 'YYYY/MM/DD'
        return 'unknown'

    def check_validity(self) -> Dict[str, Any]:
        """æª¢æŸ¥è³‡æ–™æœ‰æ•ˆæ€§"""
        print("\nğŸ” æª¢æŸ¥è³‡æ–™æœ‰æ•ˆæ€§...")

        validity_results = {}

        for col in self.df.columns:
            invalid_count = 0
            total_count = self.df[col].count()

            # æ ¹æ“šæ¬„ä½åç¨±æ¨æ¸¬é©—è­‰é¡å‹
            col_lower = col.lower()

            if 'email' in col_lower or 'mail' in col_lower:
                # é©—è­‰ email
                for value in self.df[col].dropna():
                    try:
                        validate_email(str(value))
                    except EmailNotValidError:
                        invalid_count += 1

            elif 'phone' in col_lower or 'tel' in col_lower or 'mobile' in col_lower:
                # é©—è­‰é›»è©±
                for value in self.df[col].dropna():
                    if not self._is_valid_phone(str(value)):
                        invalid_count += 1

            elif 'age' in col_lower:
                # é©—è­‰å¹´é½¡ç¯„åœ
                for value in self.df[col].dropna():
                    try:
                        age = float(value)
                        if age < 0 or age > 150:
                            invalid_count += 1
                    except (ValueError, TypeError):
                        invalid_count += 1

            elif pd.api.types.is_numeric_dtype(self.df[col]):
                # æª¢æŸ¥æ•¸å€¼ç•°å¸¸
                for value in self.df[col].dropna():
                    if np.isinf(value) or (isinstance(value, float) and np.isnan(value)):
                        invalid_count += 1

            if total_count > 0:
                validity_rate = (1 - invalid_count / total_count) * 100
                validity_results[col] = {
                    'validity_rate': float(validity_rate),
                    'invalid_count': int(invalid_count),
                    'status': 'valid' if validity_rate >= 95 else 'invalid'
                }

        self.quality_report['validity'] = validity_results

        # æ·»åŠ å•é¡Œ
        invalid_columns = [
            col for col, info in validity_results.items()
            if info['status'] == 'invalid'
        ]

        if invalid_columns:
            self.quality_report['issues'].append({
                'severity': 'high',
                'category': 'validity',
                'message': 'ç™¼ç¾ç„¡æ•ˆè³‡æ–™',
                'affected_columns': invalid_columns
            })

            self.quality_report['recommendations'].append({
                'category': 'validity',
                'priority': 'high',
                'action': 'ä¿®æ­£æˆ–ç§»é™¤ç„¡æ•ˆè³‡æ–™',
                'suggestions': [
                    'é©—è­‰ email æ ¼å¼ä¸¦ä¿®æ­£',
                    'æª¢æŸ¥æ•¸å€¼ç¯„åœæ˜¯å¦åˆç†',
                    'æ¨™æº–åŒ–é›»è©±è™Ÿç¢¼æ ¼å¼',
                    'ç§»é™¤æˆ–æ›¿æ›ç•°å¸¸å€¼'
                ]
            })

        return self.quality_report['validity']

    def _is_valid_phone(self, phone: str) -> bool:
        """æª¢æŸ¥é›»è©±è™Ÿç¢¼æœ‰æ•ˆæ€§"""
        clean_phone = re.sub(r'[\s\-\(\)]', '', phone)
        return bool(re.match(r'^\+?\d{10,15}$', clean_phone))

    def check_uniqueness(self) -> Dict[str, Any]:
        """æª¢æŸ¥è³‡æ–™å”¯ä¸€æ€§"""
        print("\nğŸ” æª¢æŸ¥è³‡æ–™å”¯ä¸€æ€§...")

        uniqueness_results = {}

        # æª¢æŸ¥é‡è¤‡åˆ—
        duplicate_rows = self.df.duplicated().sum()
        duplicate_rate = duplicate_rows / len(self.df) * 100

        uniqueness_results['duplicate_rows'] = {
            'count': int(duplicate_rows),
            'percentage': float(duplicate_rate)
        }

        # æª¢æŸ¥æ¯å€‹æ¬„ä½çš„å”¯ä¸€æ€§
        column_uniqueness = {}
        for col in self.df.columns:
            unique_count = self.df[col].nunique()
            uniqueness_rate = unique_count / self.df[col].count() * 100 if self.df[col].count() > 0 else 0

            column_uniqueness[col] = {
                'unique_count': int(unique_count),
                'uniqueness_rate': float(uniqueness_rate),
                'duplicate_count': int(len(self.df) - unique_count)
            }

        uniqueness_results['column_uniqueness'] = column_uniqueness

        self.quality_report['uniqueness'] = uniqueness_results

        if duplicate_rows > 0:
            self.quality_report['issues'].append({
                'severity': 'medium',
                'category': 'uniqueness',
                'message': f'ç™¼ç¾ {duplicate_rows} ç­†é‡è¤‡è³‡æ–™ ({duplicate_rate:.1f}%)'
            })

            self.quality_report['recommendations'].append({
                'category': 'uniqueness',
                'priority': 'medium',
                'action': 'è™•ç†é‡è¤‡è³‡æ–™',
                'suggestions': [
                    'ç§»é™¤å®Œå…¨ç›¸åŒçš„é‡è¤‡åˆ—',
                    'æª¢æŸ¥æ˜¯å¦ç‚ºåˆæ³•çš„é‡è¤‡è¨˜éŒ„',
                    'å°é—œéµæ¬„ä½é€²è¡Œå»é‡',
                    'è€ƒæ…®ä½¿ç”¨å”¯ä¸€è­˜åˆ¥ç¬¦'
                ]
            })

        return self.quality_report['uniqueness']

    def calculate_overall_score(self) -> float:
        """è¨ˆç®—æ•´é«”å“è³ªåˆ†æ•¸"""
        print("\nğŸ“Š è¨ˆç®—æ•´é«”å“è³ªåˆ†æ•¸...")

        scores = {}

        # å®Œæ•´æ€§åˆ†æ•¸ (30%)
        if 'completeness' in self.quality_report:
            scores['completeness'] = self.quality_report['completeness']['overall_completeness_rate']

        # ä¸€è‡´æ€§åˆ†æ•¸ (20%)
        if 'consistency' in self.quality_report:
            consistency_issues = self.quality_report['consistency']['issues_found']
            total_columns = len(self.df.columns)
            consistency_score = max(0, (1 - consistency_issues / total_columns) * 100)
            scores['consistency'] = consistency_score

        # æœ‰æ•ˆæ€§åˆ†æ•¸ (30%)
        if 'validity' in self.quality_report:
            validity_rates = [
                info['validity_rate']
                for info in self.quality_report['validity'].values()
            ]
            scores['validity'] = np.mean(validity_rates) if validity_rates else 100

        # å”¯ä¸€æ€§åˆ†æ•¸ (20%)
        if 'uniqueness' in self.quality_report:
            duplicate_rate = self.quality_report['uniqueness']['duplicate_rows']['percentage']
            scores['uniqueness'] = max(0, 100 - duplicate_rate)

        # è¨ˆç®—åŠ æ¬Šç¸½åˆ†
        weights = {
            'completeness': 0.30,
            'consistency': 0.20,
            'validity': 0.30,
            'uniqueness': 0.20
        }

        overall_score = sum(
            scores.get(key, 0) * weight
            for key, weight in weights.items()
        )

        self.quality_report['overall_score'] = float(overall_score)
        self.quality_report['dimension_scores'] = {
            k: float(v) for k, v in scores.items()
        }

        return overall_score

    def comprehensive_check(self) -> Dict[str, Any]:
        """åŸ·è¡Œå…¨é¢å“è³ªæª¢æŸ¥"""
        print("ğŸš€ é–‹å§‹å…¨é¢è³‡æ–™å“è³ªæª¢æŸ¥...\n")

        self.check_completeness()
        self.check_consistency()
        self.check_validity()
        self.check_uniqueness()
        self.calculate_overall_score()

        return self.quality_report

    def print_report(self):
        """åˆ—å°å“è³ªå ±å‘Š"""
        print("\n" + "="*70)
        print("ğŸ“‹ è³‡æ–™å“è³ªæª¢æ¸¬å ±å‘Š")
        print("="*70)

        # æª”æ¡ˆè³‡è¨Š
        file_info = self.quality_report['file_info']
        print(f"\nğŸ“ æª”æ¡ˆè³‡è¨Š:")
        print(f"  â€¢ æª”å: {file_info['filename']}")
        print(f"  â€¢ è³‡æ–™ç­†æ•¸: {file_info['total_rows']:,}")
        print(f"  â€¢ æ¬„ä½æ•¸: {file_info['total_columns']}")

        # æ•´é«”åˆ†æ•¸
        overall_score = self.quality_report['overall_score']
        grade = self._get_grade(overall_score)
        print(f"\nâ­ æ•´é«”å“è³ªåˆ†æ•¸: {overall_score:.1f}/100 ({grade})")

        if 'dimension_scores' in self.quality_report:
            print(f"\nğŸ“Š å„ç¶­åº¦åˆ†æ•¸:")
            scores = self.quality_report['dimension_scores']
            print(f"  â€¢ å®Œæ•´æ€§: {scores.get('completeness', 0):.1f}/100")
            print(f"  â€¢ ä¸€è‡´æ€§: {scores.get('consistency', 0):.1f}/100")
            print(f"  â€¢ æœ‰æ•ˆæ€§: {scores.get('validity', 0):.1f}/100")
            print(f"  â€¢ å”¯ä¸€æ€§: {scores.get('uniqueness', 0):.1f}/100")

        # å•é¡Œæ‘˜è¦
        issues = self.quality_report['issues']
        if issues:
            print(f"\nâš ï¸  ç™¼ç¾ {len(issues)} å€‹å“è³ªå•é¡Œ:")
            for i, issue in enumerate(issues, 1):
                severity_icon = "ğŸ”´" if issue['severity'] == 'high' else "ğŸŸ¡"
                print(f"  {severity_icon} {issue['message']}")

        # å»ºè­°
        recommendations = self.quality_report['recommendations']
        if recommendations:
            print(f"\nğŸ’¡ æ”¹é€²å»ºè­°:")
            for i, rec in enumerate(recommendations, 1):
                print(f"\n  {i}. {rec['action']} (å„ªå…ˆç´š: {rec['priority']})")
                for suggestion in rec['suggestions'][:3]:  # åªé¡¯ç¤ºå‰3æ¢
                    print(f"     â€¢ {suggestion}")

        print("\n" + "="*70)

    def _get_grade(self, score: float) -> str:
        """ç²å–ç­‰ç´š"""
        if score >= 90:
            return "å„ªç§€ A+"
        elif score >= 80:
            return "è‰¯å¥½ A"
        elif score >= 70:
            return "ä¸­ç­‰ B"
        elif score >= 60:
            return "åŠæ ¼ C"
        else:
            return "ä¸åŠæ ¼ D"

    def save_report(self, output_file: str):
        """å„²å­˜å“è³ªå ±å‘Š"""
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.quality_report, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nâœ… å ±å‘Šå·²å„²å­˜: {output_file}")


def main():
    parser = argparse.ArgumentParser(
        description='Quality Checker - æ™ºèƒ½è³‡æ–™å“è³ªæª¢æ¸¬å™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument('file', help='è¦æª¢æŸ¥çš„è³‡æ–™æª”æ¡ˆ')
    parser.add_argument('--completeness', action='store_true',
                       help='åªæª¢æŸ¥å®Œæ•´æ€§')
    parser.add_argument('--consistency', action='store_true',
                       help='åªæª¢æŸ¥ä¸€è‡´æ€§')
    parser.add_argument('--validity', action='store_true',
                       help='åªæª¢æŸ¥æœ‰æ•ˆæ€§')
    parser.add_argument('--uniqueness', action='store_true',
                       help='åªæª¢æŸ¥å”¯ä¸€æ€§')
    parser.add_argument('--report', type=str,
                       help='å„²å­˜è©³ç´°å ±å‘Š (JSON)')

    args = parser.parse_args()

    # å‰µå»ºå“è³ªæª¢æ¸¬å™¨
    checker = QualityChecker(args.file)

    # åŸ·è¡ŒæŒ‡å®šçš„æª¢æŸ¥
    if args.completeness:
        checker.check_completeness()
    elif args.consistency:
        checker.check_consistency()
    elif args.validity:
        checker.check_validity()
    elif args.uniqueness:
        checker.check_uniqueness()
    else:
        # é è¨­åŸ·è¡Œå…¨é¢æª¢æŸ¥
        checker.comprehensive_check()

    # åˆ—å°å ±å‘Š
    checker.print_report()

    # å„²å­˜å ±å‘Š
    if args.report:
        checker.save_report(args.report)


if __name__ == '__main__':
    main()
