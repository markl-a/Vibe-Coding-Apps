#!/usr/bin/env python3
"""
Data Cleaner - è³‡æ–™æ¸…ç†å’Œé©—è­‰å·¥å…·

åŠŸèƒ½ï¼š
- ç§»é™¤ç©ºç™½èˆ‡ç‰¹æ®Šå­—å…ƒ
- æ¨™æº–åŒ–æ ¼å¼ï¼ˆæ—¥æœŸã€é›»è©±ã€éƒµç®±ï¼‰
- è³‡æ–™é©—è­‰è¦å‰‡
- ç•°å¸¸å€¼æª¢æ¸¬
- è³‡æ–™é¡å‹æ¨æ–·
- æ¸…ç†å ±å‘Šç”Ÿæˆ
"""

import argparse
import sys
import re
import csv
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Tuple
import pandas as pd
import numpy as np
from email_validator import validate_email, EmailNotValidError

def load_csv(file_path: str) -> pd.DataFrame:
    """è¼‰å…¥ CSV æª”æ¡ˆ"""
    try:
        return pd.read_csv(file_path)
    except FileNotFoundError:
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ è®€å–éŒ¯èª¤: {e}")
        sys.exit(1)

def save_csv(df: pd.DataFrame, output_file: str):
    """å„²å­˜ CSV æª”æ¡ˆ"""
    df.to_csv(output_file, index=False, encoding='utf-8')
    print(f"âœ… å·²å„²å­˜: {output_file}")

def remove_whitespace(df: pd.DataFrame) -> pd.DataFrame:
    """ç§»é™¤å­—ä¸²æ¬„ä½çš„å‰å¾Œç©ºç™½"""
    for col in df.select_dtypes(include=['object']).columns:
        df[col] = df[col].str.strip()
    return df

def remove_duplicates(df: pd.DataFrame, subset: List[str] = None) -> Tuple[pd.DataFrame, int]:
    """ç§»é™¤é‡è¤‡è³‡æ–™"""
    before_count = len(df)
    df = df.drop_duplicates(subset=subset, keep='first')
    removed = before_count - len(df)
    print(f"ğŸ—‘ï¸  ç§»é™¤ {removed} ç­†é‡è¤‡è³‡æ–™")
    return df, removed

def handle_missing_values(df: pd.DataFrame, strategy: str = 'drop', fill_value: Any = None) -> pd.DataFrame:
    """è™•ç†ç¼ºå¤±å€¼"""
    if strategy == 'drop':
        before_count = len(df)
        df = df.dropna()
        removed = before_count - len(df)
        print(f"ğŸ—‘ï¸  ç§»é™¤ {removed} ç­†å«ç¼ºå¤±å€¼çš„è³‡æ–™")
    elif strategy == 'fill':
        df = df.fillna(fill_value if fill_value is not None else 'N/A')
        print(f"âœ… å·²å¡«å……ç¼ºå¤±å€¼: {fill_value}")
    elif strategy == 'forward':
        df = df.fillna(method='ffill')
        print("âœ… ä½¿ç”¨å‰ä¸€ç­†è³‡æ–™å¡«å……")
    elif strategy == 'backward':
        df = df.fillna(method='bfill')
        print("âœ… ä½¿ç”¨å¾Œä¸€ç­†è³‡æ–™å¡«å……")
    return df

def validate_email_column(df: pd.DataFrame, column: str) -> pd.DataFrame:
    """é©—è­‰éƒµç®±æ ¼å¼"""
    def is_valid_email(email):
        if pd.isna(email):
            return False
        try:
            validate_email(email)
            return True
        except EmailNotValidError:
            return False

    valid_mask = df[column].apply(is_valid_email)
    invalid_count = (~valid_mask).sum()
    print(f"ğŸ“§ éƒµç®±é©—è­‰: {valid_mask.sum()} æœ‰æ•ˆ, {invalid_count} ç„¡æ•ˆ")

    # æ¨™è¨˜ç„¡æ•ˆçš„éƒµç®±
    df[f'{column}_valid'] = valid_mask
    return df

def validate_phone_column(df: pd.DataFrame, column: str) -> pd.DataFrame:
    """é©—è­‰é›»è©±æ ¼å¼ï¼ˆç°¡å–®è¦å‰‡ï¼‰"""
    def is_valid_phone(phone):
        if pd.isna(phone):
            return False
        # ç§»é™¤å¸¸è¦‹åˆ†éš”ç¬¦è™Ÿ
        phone_clean = re.sub(r'[\s\-\(\)]', '', str(phone))
        # æª¢æŸ¥æ˜¯å¦ç‚º 10-15 ä½æ•¸å­—
        return bool(re.match(r'^\+?\d{10,15}$', phone_clean))

    valid_mask = df[column].apply(is_valid_phone)
    invalid_count = (~valid_mask).sum()
    print(f"ğŸ“± é›»è©±é©—è­‰: {valid_mask.sum()} æœ‰æ•ˆ, {invalid_count} ç„¡æ•ˆ")

    df[f'{column}_valid'] = valid_mask
    return df

def standardize_date(df: pd.DataFrame, column: str, target_format: str = '%Y-%m-%d') -> pd.DataFrame:
    """æ¨™æº–åŒ–æ—¥æœŸæ ¼å¼"""
    try:
        df[column] = pd.to_datetime(df[column], errors='coerce')
        df[column] = df[column].dt.strftime(target_format)
        print(f"ğŸ“… å·²æ¨™æº–åŒ–æ—¥æœŸæ ¼å¼: {column} -> {target_format}")
    except Exception as e:
        print(f"âŒ æ—¥æœŸè½‰æ›å¤±æ•—: {e}")
    return df

def remove_outliers(df: pd.DataFrame, columns: List[str], method: str = 'iqr', threshold: float = 1.5) -> pd.DataFrame:
    """ç§»é™¤ç•°å¸¸å€¼"""
    before_count = len(df)

    for column in columns:
        if column not in df.columns:
            print(f"âš ï¸  æ¬„ä½ä¸å­˜åœ¨: {column}")
            continue

        if not pd.api.types.is_numeric_dtype(df[column]):
            print(f"âš ï¸  {column} ä¸æ˜¯æ•¸å€¼é¡å‹")
            continue

        if method == 'iqr':
            Q1 = df[column].quantile(0.25)
            Q3 = df[column].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - threshold * IQR
            upper_bound = Q3 + threshold * IQR
            df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
        elif method == 'zscore':
            z_scores = np.abs((df[column] - df[column].mean()) / df[column].std())
            df = df[z_scores < threshold]

    removed = before_count - len(df)
    print(f"ğŸ—‘ï¸  ç§»é™¤ {removed} ç­†ç•°å¸¸å€¼")
    return df

def normalize_text(df: pd.DataFrame, columns: List[str] = None, case: str = 'lower') -> pd.DataFrame:
    """æ¨™æº–åŒ–æ–‡å­—æ ¼å¼"""
    if columns is None:
        columns = df.select_dtypes(include=['object']).columns

    for column in columns:
        if column not in df.columns:
            continue

        if case == 'lower':
            df[column] = df[column].str.lower()
        elif case == 'upper':
            df[column] = df[column].str.upper()
        elif case == 'title':
            df[column] = df[column].str.title()

    print(f"âœ… å·²æ¨™æº–åŒ–æ–‡å­—æ ¼å¼: {case}")
    return df

def infer_data_types(df: pd.DataFrame) -> pd.DataFrame:
    """è‡ªå‹•æ¨æ–·è³‡æ–™é¡å‹"""
    print("ğŸ” æ¨æ–·è³‡æ–™é¡å‹...")

    for column in df.columns:
        # å˜—è©¦è½‰æ›ç‚ºæ•¸å€¼
        try:
            df[column] = pd.to_numeric(df[column])
            print(f"  {column}: æ•¸å€¼")
            continue
        except (ValueError, TypeError):
            pass

        # å˜—è©¦è½‰æ›ç‚ºæ—¥æœŸ
        try:
            df[column] = pd.to_datetime(df[column])
            print(f"  {column}: æ—¥æœŸ")
            continue
        except (ValueError, TypeError):
            pass

        # å˜—è©¦è½‰æ›ç‚ºå¸ƒæ—å€¼
        if df[column].str.lower().isin(['true', 'false', '1', '0', 'yes', 'no']).all():
            df[column] = df[column].map({'true': True, 'false': False, '1': True, '0': False, 'yes': True, 'no': False})
            print(f"  {column}: å¸ƒæ—å€¼")
            continue

        print(f"  {column}: æ–‡å­—")

    return df

def generate_report(df: pd.DataFrame, original_df: pd.DataFrame, output_file: str = None):
    """ç”Ÿæˆæ¸…ç†å ±å‘Š"""
    report = []
    report.append("=" * 60)
    report.append("è³‡æ–™æ¸…ç†å ±å‘Š")
    report.append("=" * 60)
    report.append(f"\nğŸ“Š è³‡æ–™çµ±è¨ˆ:")
    report.append(f"  åŸå§‹è³‡æ–™ç­†æ•¸: {len(original_df)}")
    report.append(f"  æ¸…ç†å¾Œç­†æ•¸: {len(df)}")
    report.append(f"  ç§»é™¤ç­†æ•¸: {len(original_df) - len(df)}")
    report.append(f"  ä¿ç•™ç‡: {len(df) / len(original_df) * 100:.2f}%")

    report.append(f"\nğŸ“‹ æ¬„ä½è³‡è¨Š:")
    report.append(f"  æ¬„ä½æ•¸é‡: {len(df.columns)}")
    report.append(f"  æ¬„ä½åç¨±: {', '.join(df.columns)}")

    report.append(f"\nğŸ” è³‡æ–™å“è³ª:")
    report.append(f"  ç¼ºå¤±å€¼ç¸½æ•¸: {df.isnull().sum().sum()}")
    report.append(f"  é‡è¤‡è³‡æ–™: {df.duplicated().sum()}")

    report.append(f"\nğŸ“ˆ æ•¸å€¼æ¬„ä½çµ±è¨ˆ:")
    numeric_cols = df.select_dtypes(include=['number']).columns
    for col in numeric_cols:
        report.append(f"  {col}:")
        report.append(f"    å¹³å‡å€¼: {df[col].mean():.2f}")
        report.append(f"    ä¸­ä½æ•¸: {df[col].median():.2f}")
        report.append(f"    æ¨™æº–å·®: {df[col].std():.2f}")

    report_text = "\n".join(report)
    print(report_text)

    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report_text)
        print(f"\nâœ… å ±å‘Šå·²å„²å­˜: {output_file}")

def main():
    parser = argparse.ArgumentParser(
        description='Data Cleaner - è³‡æ–™æ¸…ç†å’Œé©—è­‰å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument('input', help='è¼¸å…¥ CSV æª”æ¡ˆ')
    parser.add_argument('--clean-all', action='store_true', help='åŸ·è¡Œæ‰€æœ‰æ¸…ç†æ“ä½œ')
    parser.add_argument('--remove-whitespace', action='store_true', help='ç§»é™¤ç©ºç™½')
    parser.add_argument('--deduplicate', action='store_true', help='ç§»é™¤é‡è¤‡è³‡æ–™')
    parser.add_argument('--handle-na', choices=['drop', 'fill', 'forward', 'backward'], help='è™•ç†ç¼ºå¤±å€¼')
    parser.add_argument('--fill-value', type=str, help='å¡«å……ç¼ºå¤±å€¼çš„å€¼')
    parser.add_argument('--validate-email', type=str, metavar='COLUMN', help='é©—è­‰éƒµç®±æ¬„ä½')
    parser.add_argument('--validate-phone', type=str, metavar='COLUMN', help='é©—è­‰é›»è©±æ¬„ä½')
    parser.add_argument('--standardize-date', type=str, metavar='COLUMN', help='æ¨™æº–åŒ–æ—¥æœŸæ¬„ä½')
    parser.add_argument('--date-format', type=str, default='%Y-%m-%d', help='ç›®æ¨™æ—¥æœŸæ ¼å¼')
    parser.add_argument('--remove-outliers', type=str, help='ç§»é™¤ç•°å¸¸å€¼çš„æ¬„ä½ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰')
    parser.add_argument('--outlier-method', choices=['iqr', 'zscore'], default='iqr', help='ç•°å¸¸å€¼æª¢æ¸¬æ–¹æ³•')
    parser.add_argument('--normalize-text', choices=['lower', 'upper', 'title'], help='æ¨™æº–åŒ–æ–‡å­—æ ¼å¼')
    parser.add_argument('--infer-types', action='store_true', help='è‡ªå‹•æ¨æ–·è³‡æ–™é¡å‹')
    parser.add_argument('--report', type=str, metavar='FILE', help='ç”Ÿæˆæ¸…ç†å ±å‘Š')
    parser.add_argument('-o', '--output', type=str, help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘')

    args = parser.parse_args()

    # è¼‰å…¥è³‡æ–™
    print(f"ğŸ“‚ è®€å–æª”æ¡ˆ: {args.input}")
    df = load_csv(args.input)
    original_df = df.copy()

    print(f"ğŸ“Š è³‡æ–™ç­†æ•¸: {len(df)}, æ¬„ä½æ•¸: {len(df.columns)}\n")

    # åŸ·è¡Œæ¸…ç†æ“ä½œ
    if args.clean_all or args.remove_whitespace:
        print("ğŸ§¹ ç§»é™¤ç©ºç™½...")
        df = remove_whitespace(df)

    if args.clean_all or args.deduplicate:
        print("ğŸ” ç§»é™¤é‡è¤‡...")
        df, _ = remove_duplicates(df)

    if args.handle_na or args.clean_all:
        strategy = args.handle_na or 'drop'
        print(f"ğŸ”§ è™•ç†ç¼ºå¤±å€¼: {strategy}")
        df = handle_missing_values(df, strategy, args.fill_value)

    if args.validate_email:
        print(f"ğŸ“§ é©—è­‰éƒµç®±: {args.validate_email}")
        df = validate_email_column(df, args.validate_email)

    if args.validate_phone:
        print(f"ğŸ“± é©—è­‰é›»è©±: {args.validate_phone}")
        df = validate_phone_column(df, args.validate_phone)

    if args.standardize_date:
        print(f"ğŸ“… æ¨™æº–åŒ–æ—¥æœŸ: {args.standardize_date}")
        df = standardize_date(df, args.standardize_date, args.date_format)

    if args.remove_outliers:
        columns = [c.strip() for c in args.remove_outliers.split(',')]
        print(f"ğŸ“‰ ç§»é™¤ç•°å¸¸å€¼: {', '.join(columns)}")
        df = remove_outliers(df, columns, args.outlier_method)

    if args.normalize_text:
        print(f"âœï¸  æ¨™æº–åŒ–æ–‡å­—: {args.normalize_text}")
        df = normalize_text(df, case=args.normalize_text)

    if args.infer_types:
        df = infer_data_types(df)

    # ç”Ÿæˆå ±å‘Š
    if args.report:
        generate_report(df, original_df, args.report)

    # å„²å­˜çµæœ
    if args.output:
        save_csv(df, args.output)
    else:
        print("\né è¦½æ¸…ç†çµæœ:")
        print(df.head())

if __name__ == '__main__':
    main()
