#!/usr/bin/env python3
"""
å®Œæ•´è³‡æ–™è™•ç†å·¥ä½œæµç¨‹ç¯„ä¾‹

é€™å€‹è…³æœ¬å±•ç¤ºå¦‚ä½•åœ¨ Python ç¨‹å¼ä¸­çµ„åˆä½¿ç”¨å¤šå€‹è³‡æ–™è™•ç†å·¥å…·ï¼š
1. è¼‰å…¥ä¸¦æ¸…ç†é«’è³‡æ–™
2. åˆä½µå¤šå€‹è³‡æ–™ä¾†æº
3. è½‰æ›è³‡æ–™æ ¼å¼
4. é€²è¡Œè³‡æ–™åˆ†æ
5. ç”Ÿæˆè™•ç†å ±å‘Š
6. è¼¸å‡ºè™•ç†å¾Œçš„è³‡æ–™
"""

import sys
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘ï¼Œä»¥ä¾¿å°å…¥å·¥å…·æ¨¡çµ„
sys.path.insert(0, str(Path(__file__).parent.parent))

from csv_processor import CSVProcessor
import pandas as pd
import numpy as np

def print_section(title):
    """åˆ—å°å€æ®µæ¨™é¡Œ"""
    print("\n" + "=" * 70)
    print(f"  {title}")
    print("=" * 70 + "\n")

def main():
    """ä¸»å·¥ä½œæµç¨‹"""

    # è¨­ç½®è·¯å¾‘
    examples_dir = Path(__file__).parent
    output_dir = examples_dir / "workflow_output"
    output_dir.mkdir(exist_ok=True)

    print("\n" + "ğŸš€ " * 20)
    print("è³‡æ–™è™•ç†å®Œæ•´å·¥ä½œæµç¨‹ç¯„ä¾‹")
    print("ğŸš€ " * 20)

    # ========================================
    # æ­¥é©Ÿ 1: è¼‰å…¥å’Œæ¸…ç†éŠ·å”®è³‡æ–™
    # ========================================
    print_section("æ­¥é©Ÿ 1: æ¸…ç†éŠ·å”®è³‡æ–™")

    print("ğŸ“‚ è¼‰å…¥ sales_data.csvï¼ˆåŒ…å«é«’è³‡æ–™ï¼‰...")
    sales_file = examples_dir / "sales_data.csv"

    # ä½¿ç”¨ CSVProcessor è¼‰å…¥è³‡æ–™
    sales_processor = CSVProcessor(str(sales_file))

    print(f"åŸå§‹è³‡æ–™: {len(sales_processor.rows)} åˆ—")
    print(f"æ¬„ä½: {', '.join(sales_processor.headers)}")

    # ä½¿ç”¨ pandas é€²è¡Œæ›´è¤‡é›œçš„æ¸…ç†
    df_sales = pd.read_csv(sales_file)
    print(f"\næ¸…ç†å‰çµ±è¨ˆ:")
    print(f"  - ç¸½åˆ—æ•¸: {len(df_sales)}")
    print(f"  - ç¼ºå¤±å€¼: {df_sales.isnull().sum().sum()}")
    print(f"  - é‡è¤‡åˆ—: {df_sales.duplicated().sum()}")

    # æ¸…ç†è³‡æ–™
    print("\nğŸ§¹ åŸ·è¡Œæ¸…ç†æ“ä½œ...")

    # 1. ç§»é™¤å‰å¾Œç©ºç™½
    for col in df_sales.select_dtypes(include=['object']).columns:
        df_sales[col] = df_sales[col].str.strip()
    print("  âœ“ ç§»é™¤ç©ºç™½å­—å…ƒ")

    # 2. ç§»é™¤é‡è¤‡åˆ—
    before = len(df_sales)
    df_sales = df_sales.drop_duplicates()
    print(f"  âœ“ ç§»é™¤é‡è¤‡åˆ— ({before - len(df_sales)} åˆ—)")

    # 3. è™•ç†ç¼ºå¤±å€¼
    df_sales['order_date'].fillna('2024-01-25', inplace=True)
    df_sales['quantity'].fillna(1, inplace=True)
    print("  âœ“ å¡«å……ç¼ºå¤±å€¼")

    # 4. é©—è­‰é›»å­éƒµä»¶ï¼ˆç°¡å–®é©—è­‰ï¼‰
    df_sales['email_valid'] = df_sales['customer_email'].str.contains('@', na=False)
    invalid_count = (~df_sales['email_valid']).sum()
    print(f"  âœ“ é©—è­‰é›»å­éƒµä»¶ï¼ˆ{invalid_count} å€‹ç„¡æ•ˆï¼‰")

    print(f"\næ¸…ç†å¾Œçµ±è¨ˆ:")
    print(f"  - ç¸½åˆ—æ•¸: {len(df_sales)}")
    print(f"  - ç¼ºå¤±å€¼: {df_sales.isnull().sum().sum()}")
    print(f"  - é‡è¤‡åˆ—: {df_sales.duplicated().sum()}")

    # å„²å­˜æ¸…ç†å¾Œçš„è³‡æ–™
    clean_sales_file = output_dir / "sales_cleaned.csv"
    df_sales.to_csv(clean_sales_file, index=False)
    print(f"\nâœ… å·²å„²å­˜æ¸…ç†å¾Œçš„è³‡æ–™: {clean_sales_file}")

    # ========================================
    # æ­¥é©Ÿ 2: åˆä½µå“¡å·¥è³‡æ–™
    # ========================================
    print_section("æ­¥é©Ÿ 2: åˆä½µå¤šéƒ¨é–€å“¡å·¥è³‡æ–™")

    dept1_file = examples_dir / "employees_dept1.csv"
    dept2_file = examples_dir / "employees_dept2.csv"

    print(f"ğŸ“‚ è¼‰å…¥éƒ¨é–€è³‡æ–™...")
    df_dept1 = pd.read_csv(dept1_file)
    df_dept2 = pd.read_csv(dept2_file)

    print(f"  éƒ¨é–€1: {len(df_dept1)} ä½å“¡å·¥")
    print(f"  éƒ¨é–€2: {len(df_dept2)} ä½å“¡å·¥")

    # åˆä½µè³‡æ–™
    df_employees = pd.concat([df_dept1, df_dept2], ignore_index=True)
    print(f"\nâœ… åˆä½µå®Œæˆ: å…± {len(df_employees)} ä½å“¡å·¥")

    # å„²å­˜åˆä½µå¾Œçš„è³‡æ–™
    employees_file = output_dir / "employees_all.csv"
    df_employees.to_csv(employees_file, index=False)
    print(f"âœ… å·²å„²å­˜: {employees_file}")

    # ========================================
    # æ­¥é©Ÿ 3: è³‡æ–™åˆ†æ
    # ========================================
    print_section("æ­¥é©Ÿ 3: è³‡æ–™åˆ†æèˆ‡çµ±è¨ˆ")

    # éŠ·å”®åˆ†æ
    print("ğŸ“Š éŠ·å”®è³‡æ–™åˆ†æ:")
    df_sales['total'] = df_sales['price'] * df_sales['quantity']

    # æŒ‰é¡åˆ¥çµ±è¨ˆ
    category_stats = df_sales.groupby('category').agg({
        'total': ['sum', 'mean', 'count'],
        'quantity': 'sum'
    }).round(2)

    print("\n  æŒ‰é¡åˆ¥çµ±è¨ˆ:")
    print(category_stats)

    # æŒ‰å€åŸŸçµ±è¨ˆ
    region_stats = df_sales.groupby('region').agg({
        'total': 'sum',
        'quantity': 'sum'
    }).round(2)

    print("\n  æŒ‰å€åŸŸçµ±è¨ˆ:")
    print(region_stats)

    # å“¡å·¥åˆ†æ
    print("\nğŸ“Š å“¡å·¥è³‡æ–™åˆ†æ:")
    dept_stats = df_employees.groupby('department').agg({
        'salary': ['mean', 'min', 'max'],
        'emp_id': 'count'
    }).round(2)

    print("\n  æŒ‰éƒ¨é–€çµ±è¨ˆ:")
    print(dept_stats)

    # ========================================
    # æ­¥é©Ÿ 4: è³‡æ–™è½‰æ›
    # ========================================
    print_section("æ­¥é©Ÿ 4: è³‡æ–™æ ¼å¼è½‰æ›")

    # è½‰æ›ç‚º JSON
    print("ğŸ”„ è½‰æ›éŠ·å”®è³‡æ–™ç‚º JSON...")
    sales_json = df_sales.to_dict(orient='records')
    json_file = output_dir / "sales_data.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(sales_json, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²å„²å­˜: {json_file}")

    # è½‰æ›å“¡å·¥è³‡æ–™ç‚º JSON
    print("\nğŸ”„ è½‰æ›å“¡å·¥è³‡æ–™ç‚º JSON...")
    employees_json = df_employees.to_dict(orient='records')
    employees_json_file = output_dir / "employees_all.json"
    with open(employees_json_file, 'w', encoding='utf-8') as f:
        json.dump(employees_json, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²å„²å­˜: {employees_json_file}")

    # ========================================
    # æ­¥é©Ÿ 5: ç”Ÿæˆè™•ç†å ±å‘Š
    # ========================================
    print_section("æ­¥é©Ÿ 5: ç”Ÿæˆè™•ç†å ±å‘Š")

    report = {
        'processing_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'workflow': 'å®Œæ•´è³‡æ–™è™•ç†æµç¨‹',
        'steps': [
            {
                'step': 1,
                'name': 'æ¸…ç†éŠ·å”®è³‡æ–™',
                'input_file': 'sales_data.csv',
                'output_file': 'sales_cleaned.csv',
                'original_rows': len(pd.read_csv(sales_file)),
                'processed_rows': len(df_sales),
                'operations': [
                    'ç§»é™¤ç©ºç™½å­—å…ƒ',
                    'ç§»é™¤é‡è¤‡åˆ—',
                    'å¡«å……ç¼ºå¤±å€¼',
                    'é©—è­‰é›»å­éƒµä»¶'
                ]
            },
            {
                'step': 2,
                'name': 'åˆä½µå“¡å·¥è³‡æ–™',
                'input_files': ['employees_dept1.csv', 'employees_dept2.csv'],
                'output_file': 'employees_all.csv',
                'total_employees': len(df_employees),
                'departments': df_employees['department'].unique().tolist()
            },
            {
                'step': 3,
                'name': 'è³‡æ–™åˆ†æ',
                'sales_analysis': {
                    'total_revenue': float(df_sales['total'].sum()),
                    'total_orders': len(df_sales),
                    'categories': df_sales['category'].unique().tolist(),
                    'regions': df_sales['region'].unique().tolist()
                },
                'employee_analysis': {
                    'total_employees': len(df_employees),
                    'average_salary': float(df_employees['salary'].mean()),
                    'departments': len(df_employees['department'].unique())
                }
            }
        ],
        'summary': {
            'files_processed': 3,
            'total_records': len(df_sales) + len(df_employees),
            'output_formats': ['CSV', 'JSON'],
            'success': True
        }
    }

    # å„²å­˜ JSON å ±å‘Š
    report_json_file = output_dir / "processing_report.json"
    with open(report_json_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    # å„²å­˜æ–‡å­—å ±å‘Š
    report_txt_file = output_dir / "processing_report.txt"
    with open(report_txt_file, 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "\n")
        f.write("è³‡æ–™è™•ç†å®Œæ•´å·¥ä½œæµç¨‹å ±å‘Š\n")
        f.write("=" * 70 + "\n\n")
        f.write(f"è™•ç†æ™‚é–“: {report['processing_date']}\n\n")

        f.write("è™•ç†æ­¥é©Ÿ:\n")
        f.write("-" * 70 + "\n\n")

        for step in report['steps']:
            f.write(f"æ­¥é©Ÿ {step['step']}: {step['name']}\n")
            if 'input_file' in step:
                f.write(f"  è¼¸å…¥æª”æ¡ˆ: {step['input_file']}\n")
            if 'input_files' in step:
                f.write(f"  è¼¸å…¥æª”æ¡ˆ: {', '.join(step['input_files'])}\n")
            if 'output_file' in step:
                f.write(f"  è¼¸å‡ºæª”æ¡ˆ: {step['output_file']}\n")
            f.write("\n")

        f.write("\nç¸½çµ:\n")
        f.write("-" * 70 + "\n")
        f.write(f"è™•ç†æª”æ¡ˆæ•¸: {report['summary']['files_processed']}\n")
        f.write(f"è™•ç†è¨˜éŒ„æ•¸: {report['summary']['total_records']}\n")
        f.write(f"è¼¸å‡ºæ ¼å¼: {', '.join(report['summary']['output_formats'])}\n")
        f.write(f"è™•ç†ç‹€æ…‹: {'æˆåŠŸ âœ…' if report['summary']['success'] else 'å¤±æ•— âŒ'}\n")

        f.write("\n" + "=" * 70 + "\n")

    print(f"âœ… å·²å„²å­˜ JSON å ±å‘Š: {report_json_file}")
    print(f"âœ… å·²å„²å­˜æ–‡å­—å ±å‘Š: {report_txt_file}")

    # ========================================
    # æ­¥é©Ÿ 6: ç”Ÿæˆæ‘˜è¦çµ±è¨ˆ
    # ========================================
    print_section("æ­¥é©Ÿ 6: æ‘˜è¦çµ±è¨ˆ")

    # å‰µå»ºæ‘˜è¦è³‡æ–™æ¡†
    summary_data = {
        'è³‡æ–™é›†': ['éŠ·å”®è³‡æ–™', 'å“¡å·¥è³‡æ–™'],
        'è¨˜éŒ„æ•¸': [len(df_sales), len(df_employees)],
        'æ¬„ä½æ•¸': [len(df_sales.columns), len(df_employees.columns)],
        'ç¼ºå¤±å€¼': [df_sales.isnull().sum().sum(), df_employees.isnull().sum().sum()],
        'é‡è¤‡åˆ—': [df_sales.duplicated().sum(), df_employees.duplicated().sum()]
    }

    df_summary = pd.DataFrame(summary_data)
    print(df_summary.to_string(index=False))

    # å„²å­˜æ‘˜è¦
    summary_file = output_dir / "summary.csv"
    df_summary.to_csv(summary_file, index=False)
    print(f"\nâœ… å·²å„²å­˜æ‘˜è¦: {summary_file}")

    # ========================================
    # å®Œæˆ
    # ========================================
    print_section("è™•ç†å®Œæˆï¼")

    print("âœ… æ‰€æœ‰æ­¥é©Ÿå·²å®Œæˆ")
    print(f"\nğŸ“ è¼¸å‡ºç›®éŒ„: {output_dir}")
    print("\nç”Ÿæˆçš„æª”æ¡ˆ:")

    output_files = sorted(output_dir.glob("*"))
    for i, file_path in enumerate(output_files, 1):
        file_size = file_path.stat().st_size
        print(f"  {i}. {file_path.name} ({file_size:,} bytes)")

    print("\n" + "ğŸ‰ " * 20)
    print("å·¥ä½œæµç¨‹åŸ·è¡ŒæˆåŠŸï¼")
    print("ğŸ‰ " * 20 + "\n")

    # è¿”å›è™•ç†çµæœ
    return {
        'sales_data': df_sales,
        'employees_data': df_employees,
        'report': report,
        'output_dir': output_dir
    }


if __name__ == '__main__':
    try:
        results = main()
        print("\næç¤º: æ‚¨å¯ä»¥æŸ¥çœ‹ workflow_output/ ç›®éŒ„ä¸­çš„æ‰€æœ‰è¼¸å‡ºæª”æ¡ˆ")
        print("      æˆ–åœ¨ Python ä¸­å°å…¥æ­¤æ¨¡çµ„ä¾†ä½¿ç”¨ main() å‡½æ•¸")

    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
