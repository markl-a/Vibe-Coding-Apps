# ğŸ“š Data Processing Tools - å®Œæ•´ä½¿ç”¨æ•™ç¨‹

æœ¬æ•™ç¨‹å°‡å¸¶æ‚¨å®Œæ•´é«”é©—æ‰€æœ‰è³‡æ–™è™•ç†å·¥å…·çš„åŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. å®‰è£ä¾è³´

```bash
cd tools-utilities/data-processing
pip install -r requirements.txt
```

### 2. æº–å‚™æ¸¬è©¦è³‡æ–™

æˆ‘å€‘å·²ç¶“æä¾›äº†æ¸¬è©¦è³‡æ–™æª”æ¡ˆ `test_analysis_data.csv`,åŒ…å« 20 ç­†å“¡å·¥è³‡æ–™ã€‚

## ğŸ“Š å·¥å…·ä½¿ç”¨æŒ‡å—

### 1. è³‡æ–™åˆ†æå™¨ (data_analyzer.py)

é€²è¡Œå…¨é¢çš„è³‡æ–™åˆ†æ,ç²å–çµ±è¨ˆè¦‹è§£ã€‚

```bash
# åŸ·è¡Œå®Œæ•´åˆ†æ
python data_analyzer.py examples/test_analysis_data.csv --full

# åªåŸ·è¡ŒåŸºæœ¬çµ±è¨ˆ
python data_analyzer.py examples/test_analysis_data.csv --basic

# åªåŸ·è¡Œç›¸é—œæ€§åˆ†æ
python data_analyzer.py examples/test_analysis_data.csv --correlation

# å„²å­˜åˆ†æå ±å‘Š
python data_analyzer.py examples/test_analysis_data.csv --full --report analysis_report.json --format html
```

**è¼¸å‡ºç¤ºä¾‹:**
- è³‡æ–™å®Œæ•´æ€§è©•ä¼°
- æ¬„ä½çµ±è¨ˆæ‘˜è¦
- ç›¸é—œæ€§çŸ©é™£
- åˆ†å¸ƒåˆ†æ
- ç•°å¸¸å€¼è­˜åˆ¥
- AI é©…å‹•çš„æ™ºèƒ½è¦‹è§£

### 2. è³‡æ–™è¦–è¦ºåŒ–å·¥å…· (data_visualizer.py)

è‡ªå‹•ç”Ÿæˆå°ˆæ¥­åœ–è¡¨ã€‚

```bash
# è‡ªå‹•è¦–è¦ºåŒ–
python data_visualizer.py examples/test_analysis_data.csv --auto

# å‰µå»ºå„€è¡¨æ¿
python data_visualizer.py examples/test_analysis_data.csv --dashboard

# ç¹ªè£½ç‰¹å®šæ¬„ä½çš„åˆ†å¸ƒåœ–
python data_visualizer.py examples/test_analysis_data.csv --distribution age

# ç¹ªè£½ç›¸é—œæ€§çŸ©é™£
python data_visualizer.py examples/test_analysis_data.csv --correlation

# ç¹ªè£½æ•£é»åœ–
python data_visualizer.py examples/test_analysis_data.csv --scatter age salary

# æŒ‡å®šè¼¸å‡ºç›®éŒ„
python data_visualizer.py examples/test_analysis_data.csv --auto --output-dir my_charts
```

**ç”Ÿæˆçš„åœ–è¡¨:**
- åˆ†å¸ƒç›´æ–¹åœ–
- ç›¸é—œæ€§ç†±åŠ›åœ–
- æ•£é»åœ–(å«è¶¨å‹¢ç·š)
- æŸ±ç‹€åœ–
- åœ“é¤…åœ–
- ç¶œåˆå„€è¡¨æ¿

### 3. è³‡æ–™å“è³ªæª¢æ¸¬å™¨ (quality_checker.py)

è©•ä¼°è³‡æ–™å“è³ªä¸¦ç²å¾—æ”¹é€²å»ºè­°ã€‚

```bash
# åŸ·è¡Œå…¨é¢å“è³ªæª¢æŸ¥
python quality_checker.py examples/test_analysis_data.csv

# åªæª¢æŸ¥å®Œæ•´æ€§
python quality_checker.py examples/test_analysis_data.csv --completeness

# åªæª¢æŸ¥ä¸€è‡´æ€§
python quality_checker.py examples/test_analysis_data.csv --consistency

# åªæª¢æŸ¥æœ‰æ•ˆæ€§
python quality_checker.py examples/test_analysis_data.csv --validity

# å„²å­˜è©³ç´°å ±å‘Š
python quality_checker.py examples/test_analysis_data.csv --report quality_report.json
```

**è©•ä¼°ç¶­åº¦:**
- âœ… å®Œæ•´æ€§ (Completeness) - 30%
- âœ… ä¸€è‡´æ€§ (Consistency) - 20%
- âœ… æœ‰æ•ˆæ€§ (Validity) - 30%
- âœ… å”¯ä¸€æ€§ (Uniqueness) - 20%

**è¼¸å‡º:** ç¸½åˆ† 0-100,ç­‰ç´š A+/A/B/C/D

### 4. ç•°å¸¸æª¢æ¸¬å™¨ (anomaly_detector.py)

è­˜åˆ¥è³‡æ–™ä¸­çš„ç•°å¸¸å€¼ã€‚

```bash
# åŸ·è¡Œå…¨é¢ç•°å¸¸æª¢æ¸¬
python anomaly_detector.py examples/test_analysis_data.csv

# ä½¿ç”¨ Z-score æ–¹æ³•
python anomaly_detector.py examples/test_analysis_data.csv --method zscore --threshold 3.0

# ä½¿ç”¨ IQR æ–¹æ³•
python anomaly_detector.py examples/test_analysis_data.csv --method iqr --threshold 1.5

# åªä½¿ç”¨çµ±è¨ˆæ–¹æ³•
python anomaly_detector.py examples/test_analysis_data.csv --statistical-only

# åªä½¿ç”¨æ©Ÿå™¨å­¸ç¿’æ–¹æ³•
python anomaly_detector.py examples/test_analysis_data.csv --ml-only --contamination 0.05

# æ¨™è¨˜ç•°å¸¸ä¸¦å„²å­˜
python anomaly_detector.py examples/test_analysis_data.csv --mark marked_data.csv

# å„²å­˜ç•°å¸¸å ±å‘Š
python anomaly_detector.py examples/test_analysis_data.csv --report anomaly_report.json
```

**æª¢æ¸¬æ–¹æ³•:**
- çµ±è¨ˆæ–¹æ³•: IQR, Z-score, Modified Z-score
- æ©Ÿå™¨å­¸ç¿’: Isolation Forest
- æ¨¡å¼æª¢æ¸¬: å¸¸æ•¸å€¼ã€éåº¦é‡è¤‡ã€çªç„¶è·³è®Š
- ç›¸é—œæ€§ç•°å¸¸

### 5. CSV è™•ç†å™¨ (csv_processor.py)

å¼·å¤§çš„ CSV æª”æ¡ˆè™•ç†å·¥å…·ã€‚

```bash
# æŸ¥çœ‹ CSV è³‡è¨Š
python csv_processor.py examples/test_analysis_data.csv --info

# é¸æ“‡ç‰¹å®šæ¬„ä½
python csv_processor.py examples/test_analysis_data.csv --select "name,age,salary" -o selected.csv

# å»é™¤é‡è¤‡
python csv_processor.py examples/test_analysis_data.csv --deduplicate -o clean.csv

# å¡«å……ç¼ºå¤±å€¼
python csv_processor.py examples/test_analysis_data.csv --fill-na "N/A" -o filled.csv

# è½‰æ›ç‚º JSON
python csv_processor.py examples/test_analysis_data.csv --to-json output.json

# åˆä½µå¤šå€‹ CSV
python csv_processor.py file1.csv file2.csv --merge -o merged.csv
```

### 6. JSON è½‰æ›å™¨ (json_transformer.py)

JSON è³‡æ–™è™•ç†å·¥å…·ã€‚

```bash
# ç¾åŒ– JSON
python json_transformer.py data.json --prettify

# JSONPath æŸ¥è©¢
python json_transformer.py data.json --query "$.users[*].name"

# è½‰æ›ç‚º CSV
python json_transformer.py data.json --to-csv output.csv

# åˆä½µå¤šå€‹ JSON
python json_transformer.py file1.json file2.json --merge deep -o merged.json

# å±•å¹³å·¢ç‹€ JSON
python json_transformer.py data.json --flatten -o flattened.json
```

### 7. è³‡æ–™æ¸…ç†å™¨ (data_cleaner.py)

è‡ªå‹•åŒ–è³‡æ–™æ¸…ç†ã€‚

```bash
# åŸ·è¡Œæ‰€æœ‰æ¸…ç†æ“ä½œ
python data_cleaner.py data.csv --clean-all -o clean.csv

# ç§»é™¤ç©ºç™½
python data_cleaner.py data.csv --remove-whitespace -o cleaned.csv

# å»é™¤é‡è¤‡
python data_cleaner.py data.csv --deduplicate -o unique.csv

# è™•ç†ç¼ºå¤±å€¼
python data_cleaner.py data.csv --handle-na drop -o no_nulls.csv
python data_cleaner.py data.csv --handle-na fill --fill-value "Unknown" -o filled.csv

# é©—è­‰ email
python data_cleaner.py data.csv --validate-email "email_column" -o validated.csv

# æ¨™æº–åŒ–æ—¥æœŸ
python data_cleaner.py data.csv --standardize-date "join_date" --date-format "%Y-%m-%d" -o std_date.csv

# ç§»é™¤ç•°å¸¸å€¼
python data_cleaner.py data.csv --remove-outliers "age,salary" --outlier-method iqr -o no_outliers.csv

# ç”Ÿæˆæ¸…ç†å ±å‘Š
python data_cleaner.py data.csv --clean-all --report cleaning_report.txt -o clean.csv
```

### 8. è³‡æ–™åˆä½µå™¨ (data_merger.py)

åˆä½µå¤šå€‹è³‡æ–™ä¾†æºã€‚

```bash
# ç°¡å–®å †ç–Šåˆä½µ
python data_merger.py file1.csv file2.csv -o merged.csv

# ä½¿ç”¨éµå€¼åˆä½µ (é¡ä¼¼ SQL JOIN)
python data_merger.py users.csv orders.csv --key "user_id" --join inner -o merged.csv

# ä¸åŒ JOIN é¡å‹
python data_merger.py file1.csv file2.csv --key "id" --join outer -o merged.csv
python data_merger.py file1.csv file2.csv --key "id" --join left -o merged.csv

# æ™ºèƒ½åˆä½µ (è‡ªå‹•åµæ¸¬ç›¸ä¼¼æ¬„ä½)
python data_merger.py file1.csv file2.csv --smart -o merged.csv

# å»é™¤é‡è¤‡
python data_merger.py file1.csv file2.csv --deduplicate --dedup-strategy first -o merged.csv

# é¡¯ç¤ºåˆä½µå ±å‘Š
python data_merger.py file1.csv file2.csv --report -o merged.csv
```

### 9. æ‰¹æ¬¡è™•ç†å™¨ (batch_processor.py)

æ‰¹æ¬¡è™•ç†å¤šå€‹æª”æ¡ˆã€‚

```bash
# æ‰¹æ¬¡è½‰æ›æ ¼å¼
python batch_processor.py --input "data/*.csv" --convert json --output converted/

# æ‰¹æ¬¡æ¸…ç†
python batch_processor.py --input "data/*.csv" --clean --output cleaned/

# æ‰¹æ¬¡é©—è­‰
python batch_processor.py --input "data/*.csv" --validate

# æ‰¹æ¬¡åˆ†æ
python batch_processor.py --input "data/*.csv" --analyze

# åˆä½µå¤šå€‹æª”æ¡ˆ
python batch_processor.py --input "data/*.csv" --merge --output final.csv

# å¹³è¡Œè™•ç† (ä½¿ç”¨å¤šå€‹å·¥ä½œè€…)
python batch_processor.py --input "data/*.csv" --convert json --workers 8 --output converted/

# å„²å­˜è™•ç†å ±å‘Š
python batch_processor.py --input "data/*.csv" --convert json --report process_report.json
```

### 10. Excel è½‰æ›å™¨ (excel_converter.py)

Excel æª”æ¡ˆè™•ç†ã€‚

```bash
# è½‰æ›ç‚º CSV
python excel_converter.py data.xlsx --to-csv output.csv

# æŒ‡å®šå·¥ä½œè¡¨
python excel_converter.py data.xlsx --sheet "Sheet1" --to-json output.json

# åˆä½µå¤šå€‹å·¥ä½œè¡¨
python excel_converter.py data.xlsx --merge-sheets --output merged.csv

# æ‰¹æ¬¡è½‰æ›
python excel_converter.py *.xlsx --batch --to-csv --output converted/
```

### 11. API è³‡æ–™æå–å™¨ (api_fetcher.py)

å¾ REST API æå–è³‡æ–™ã€‚

```bash
# å–®ä¸€è«‹æ±‚
python api_fetcher.py https://api.example.com /users/1

# åˆ†é è«‹æ±‚
python api_fetcher.py https://api.example.com /users --paginated --per-page 50 -o users.json

# å¸¶èªè­‰
python api_fetcher.py https://api.example.com /data \
    --header "Authorization: Bearer YOUR_TOKEN" \
    --paginated -o data.csv

# POST è«‹æ±‚
python api_fetcher.py https://api.example.com /search \
    --method POST \
    --data '{"query": "test"}' \
    -o results.json

# é™åˆ¶æœ€å¤§é æ•¸
python api_fetcher.py https://api.example.com /users \
    --paginated --max-pages 10 -o users.csv
```

## ğŸ”„ å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹

### æƒ…å¢ƒ:è™•ç†éŠ·å”®è³‡æ–™

```bash
# 1. å¾ API æå–è³‡æ–™
python api_fetcher.py https://api.company.com /sales \
    --paginated --per-page 1000 -o raw_sales.json

# 2. è½‰æ›ç‚º CSV
python json_transformer.py raw_sales.json --to-csv sales.csv

# 3. æª¢æŸ¥è³‡æ–™å“è³ª
python quality_checker.py sales.csv --report quality_report.json

# 4. æ¸…ç†è³‡æ–™
python data_cleaner.py sales.csv \
    --clean-all \
    --remove-outliers "amount" \
    -o clean_sales.csv

# 5. åˆ†æè³‡æ–™
python data_analyzer.py clean_sales.csv \
    --full \
    --report analysis_report.html \
    --format html

# 6. è¦–è¦ºåŒ–
python data_visualizer.py clean_sales.csv --auto --dashboard

# 7. æª¢æ¸¬ç•°å¸¸
python anomaly_detector.py clean_sales.csv \
    --mark sales_with_anomalies.csv \
    --report anomaly_report.json
```

## ğŸ’¡ æœ€ä½³å¯¦è¸

### 1. è³‡æ–™è™•ç†æµç¨‹

```
åŸå§‹è³‡æ–™ â†’ å“è³ªæª¢æŸ¥ â†’ æ¸…ç† â†’ é©—è­‰ â†’ åˆ†æ â†’ è¦–è¦ºåŒ– â†’ å ±å‘Š
```

### 2. å§‹çµ‚å‚™ä»½åŸå§‹è³‡æ–™

```bash
cp original_data.csv backup_data.csv
```

### 3. ä½¿ç”¨ç®¡é“çµ„åˆå·¥å…·

```bash
# æ¸…ç† â†’ å»é‡ â†’ åˆ†æ
python data_cleaner.py raw.csv --clean-all -o clean.csv && \
python csv_processor.py clean.csv --deduplicate -o unique.csv && \
python data_analyzer.py unique.csv --full --report report.html
```

### 4. æ‰¹æ¬¡è™•ç†å¤§é‡æª”æ¡ˆ

```bash
# ä½¿ç”¨è¬ç”¨å­—å…ƒè™•ç†å¤šå€‹æª”æ¡ˆ
python batch_processor.py --input "data/*.csv" --clean --workers 4
```

### 5. çµ„åˆä¸åŒæ ¼å¼

```bash
# CSV + JSON â†’ åˆä½µçš„ Excel
python data_merger.py sales.csv orders.json -o combined.xlsx
```

## ğŸ“ é€²éšæŠ€å·§

### 1. è‡ªè¨‚è³‡æ–™ç®¡é“

å‰µå»ºä¸€å€‹ Shell è…³æœ¬è‡ªå‹•åŒ–æ•´å€‹æµç¨‹:

```bash
#!/bin/bash
# data_pipeline.sh

echo "ğŸš€ é–‹å§‹è³‡æ–™è™•ç†ç®¡é“..."

# æå–
python api_fetcher.py $API_URL /data --paginated -o raw.json

# è½‰æ›
python json_transformer.py raw.json --to-csv data.csv

# å“è³ªæª¢æŸ¥
python quality_checker.py data.csv --report quality.json

# æ¸…ç†
python data_cleaner.py data.csv --clean-all -o clean.csv

# åˆ†æèˆ‡è¦–è¦ºåŒ–
python data_analyzer.py clean.csv --full --report analysis.html
python data_visualizer.py clean.csv --auto

echo "âœ… ç®¡é“å®Œæˆ!"
```

### 2. ä½¿ç”¨é…ç½®æª”æ¡ˆ

å‰µå»º `config.json` ä¾†ç®¡ç†è¨­å®š:

```json
{
  "api": {
    "base_url": "https://api.example.com",
    "headers": {
      "Authorization": "Bearer TOKEN"
    }
  },
  "processing": {
    "remove_outliers": true,
    "fill_missing": "mean",
    "quality_threshold": 80
  },
  "output": {
    "format": "csv",
    "encoding": "utf-8"
  }
}
```

### 3. å®šæœŸè‡ªå‹•åŒ–è™•ç†

ä½¿ç”¨ cron æˆ– Task Scheduler:

```cron
# æ¯å¤©å‡Œæ™¨ 2 é»åŸ·è¡Œ
0 2 * * * /path/to/data_pipeline.sh
```

## â“ å¸¸è¦‹å•é¡Œ

### Q: å¦‚ä½•è™•ç†å¤§å‹æª”æ¡ˆ?

ä½¿ç”¨æ‰¹æ¬¡è™•ç†å™¨çš„åˆ†å¡ŠåŠŸèƒ½:

```bash
python batch_processor.py --input large_file.csv --chunk-size 10000
```

### Q: å¦‚ä½•åˆä½µä¸åŒæ ¼å¼çš„æª”æ¡ˆ?

è³‡æ–™åˆä½µå™¨æ”¯æ´æ··åˆæ ¼å¼:

```bash
python data_merger.py data.csv info.json stats.xlsx -o combined.csv
```

### Q: å¦‚ä½•è‡ªè¨‚è¦–è¦ºåŒ–æ¨£å¼?

ç·¨è¼¯ `data_visualizer.py` ä¸­çš„æ¨£å¼è¨­å®šæˆ–ä½¿ç”¨ matplotlib æ¨£å¼è¡¨ã€‚

### Q: ç•°å¸¸æª¢æ¸¬çš„é–¾å€¼å¦‚ä½•é¸æ“‡?

- IQR æ–¹æ³•: 1.5 (æ¨™æº–), 3.0 (å¯¬é¬†)
- Z-score: 3.0 (æ¨™æº–), 2.5 (åš´æ ¼)
- ML contamination: 0.1 (10% ç•°å¸¸é æœŸ)

## ğŸ“– æ›´å¤šè³‡æº

- æŸ¥çœ‹å„å·¥å…·çš„ `--help` ç²å–è©³ç´°é¸é …
- åƒè€ƒ `examples/` ç›®éŒ„ä¸­çš„ç¯„ä¾‹è³‡æ–™
- é–±è®€ä¸» README.md äº†è§£æ¶æ§‹è¨­è¨ˆ

## ğŸ¤ è²¢ç»

æ­¡è¿æäº¤å•é¡Œå’Œæ”¹é€²å»ºè­°!

---

**Happy Data Processing!** ğŸ“Šâœ¨
