#!/usr/bin/env python3
"""
performance_profiler.py - æ€§èƒ½åˆ†æå·¥å…·
åˆ†æç¨‹å¼ç¢¼æ€§èƒ½ä¸¦æä¾›å„ªåŒ–å»ºè­°
"""

import os
import sys
import argparse
import cProfile
import pstats
import io
import time
import json
from pathlib import Path
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass
from datetime import datetime
import tracemalloc
import linecache


@dataclass
class PerformanceMetric:
    """æ€§èƒ½æŒ‡æ¨™"""
    function_name: str
    calls: int
    total_time: float
    cumulative_time: float
    per_call_time: float
    filename: str
    line_number: int


@dataclass
class MemorySnapshot:
    """å…§å­˜å¿«ç…§"""
    current: float  # MB
    peak: float  # MB
    top_allocations: List[Dict]


class PerformanceProfiler:
    """æ€§èƒ½åˆ†æå™¨"""

    def __init__(self):
        self.profiler = None
        self.results = {}
        self.memory_enabled = False

    def profile_function(self, func: Callable, *args, **kwargs) -> Dict:
        """åˆ†æå–®å€‹å‡½æ•¸çš„æ€§èƒ½"""
        # CPU åˆ†æ
        profiler = cProfile.Profile()

        # å…§å­˜è¿½è¹¤
        if self.memory_enabled:
            tracemalloc.start()

        start_time = time.perf_counter()

        # åŸ·è¡Œå‡½æ•¸
        profiler.enable()
        try:
            result = func(*args, **kwargs)
            success = True
            error = None
        except Exception as e:
            result = None
            success = False
            error = str(e)
        finally:
            profiler.disable()

        end_time = time.perf_counter()
        execution_time = end_time - start_time

        # æ”¶é›†çµ±è¨ˆ
        stats = self._extract_stats(profiler)

        # å…§å­˜çµ±è¨ˆ
        memory_stats = None
        if self.memory_enabled:
            memory_stats = self._get_memory_stats()
            tracemalloc.stop()

        return {
            'function': func.__name__,
            'success': success,
            'error': error,
            'execution_time': execution_time,
            'cpu_stats': stats,
            'memory_stats': memory_stats,
            'result': result
        }

    def profile_script(self, script_path: str) -> Dict:
        """åˆ†ææ•´å€‹è…³æœ¬çš„æ€§èƒ½"""
        path = Path(script_path)

        if not path.exists():
            raise FileNotFoundError(f"è…³æœ¬ä¸å­˜åœ¨: {script_path}")

        # è®€å–è…³æœ¬
        with open(path, 'r', encoding='utf-8') as f:
            code = f.read()

        # å‰µå»ºå‘½åç©ºé–“
        namespace = {
            '__name__': '__main__',
            '__file__': str(path)
        }

        # å•Ÿç”¨åˆ†æå™¨
        profiler = cProfile.Profile()

        if self.memory_enabled:
            tracemalloc.start()

        start_time = time.perf_counter()

        # åŸ·è¡Œè…³æœ¬
        profiler.enable()
        try:
            exec(code, namespace)
            success = True
            error = None
        except Exception as e:
            success = False
            error = str(e)
            traceback.print_exc()
        finally:
            profiler.disable()

        end_time = time.perf_counter()
        execution_time = end_time - start_time

        # æ”¶é›†çµ±è¨ˆ
        stats = self._extract_stats(profiler)

        # å…§å­˜çµ±è¨ˆ
        memory_stats = None
        if self.memory_enabled:
            memory_stats = self._get_memory_stats()
            tracemalloc.stop()

        # æ€§èƒ½å»ºè­°
        recommendations = self._generate_recommendations(stats, execution_time)

        return {
            'script': str(path),
            'success': success,
            'error': error,
            'execution_time': execution_time,
            'cpu_stats': stats,
            'memory_stats': memory_stats,
            'recommendations': recommendations
        }

    def profile_module(self, module_name: str, function_name: Optional[str] = None) -> Dict:
        """åˆ†ææ¨¡çµ„çš„æ€§èƒ½"""
        try:
            # å‹•æ…‹å°å…¥æ¨¡çµ„
            import importlib
            module = importlib.import_module(module_name)

            if function_name:
                # åˆ†æç‰¹å®šå‡½æ•¸
                func = getattr(module, function_name)
                return self.profile_function(func)
            else:
                # åˆ†ææ•´å€‹æ¨¡çµ„
                profiler = cProfile.Profile()
                profiler.enable()

                # é‡æ–°åŠ è¼‰æ¨¡çµ„
                importlib.reload(module)

                profiler.disable()

                stats = self._extract_stats(profiler)

                return {
                    'module': module_name,
                    'cpu_stats': stats
                }

        except ImportError as e:
            return {
                'module': module_name,
                'error': f"ç„¡æ³•å°å…¥æ¨¡çµ„: {e}"
            }
        except AttributeError as e:
            return {
                'module': module_name,
                'function': function_name,
                'error': f"å‡½æ•¸ä¸å­˜åœ¨: {e}"
            }

    def benchmark(self, func: Callable, iterations: int = 100,
                 warmup: int = 10, *args, **kwargs) -> Dict:
        """åŸºæº–æ¸¬è©¦"""
        print(f"åŸ·è¡ŒåŸºæº–æ¸¬è©¦: {func.__name__}")
        print(f"ç†±èº«è¿­ä»£: {warmup}, æ¸¬è©¦è¿­ä»£: {iterations}")

        # ç†±èº«
        for _ in range(warmup):
            func(*args, **kwargs)

        # åŸºæº–æ¸¬è©¦
        times = []
        for i in range(iterations):
            start = time.perf_counter()
            func(*args, **kwargs)
            end = time.perf_counter()
            times.append(end - start)

            if (i + 1) % 10 == 0:
                print(f"é€²åº¦: {i + 1}/{iterations}")

        # çµ±è¨ˆ
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)

        # è¨ˆç®—æ¨™æº–å·®
        variance = sum((t - avg_time) ** 2 for t in times) / len(times)
        std_dev = variance ** 0.5

        return {
            'function': func.__name__,
            'iterations': iterations,
            'warmup': warmup,
            'average_time': avg_time,
            'min_time': min_time,
            'max_time': max_time,
            'std_dev': std_dev,
            'total_time': sum(times),
            'throughput': 1.0 / avg_time if avg_time > 0 else 0
        }

    def compare_functions(self, functions: List[Callable],
                         iterations: int = 100, *args, **kwargs) -> Dict:
        """æ¯”è¼ƒå¤šå€‹å‡½æ•¸çš„æ€§èƒ½"""
        results = []

        for func in functions:
            benchmark_result = self.benchmark(func, iterations, *args, **kwargs)
            results.append(benchmark_result)

        # æ‰¾å‡ºæœ€å¿«çš„å‡½æ•¸
        best = min(results, key=lambda x: x['average_time'])

        # è¨ˆç®—ç›¸å°æ€§èƒ½
        for result in results:
            result['relative_performance'] = result['average_time'] / best['average_time']
            result['speedup'] = best['average_time'] / result['average_time']

        return {
            'results': results,
            'best_function': best['function'],
            'comparison': results
        }

    def _extract_stats(self, profiler: cProfile.Profile) -> List[Dict]:
        """æå–çµ±è¨ˆä¿¡æ¯"""
        stream = io.StringIO()
        stats = pstats.Stats(profiler, stream=stream)
        stats.strip_dirs()
        stats.sort_stats('cumulative')

        # ç²å–å‰ 20 å€‹æœ€è€—æ™‚çš„å‡½æ•¸
        metrics = []
        for func, (cc, nc, tt, ct, callers) in stats.stats.items():
            filename, line, func_name = func

            metrics.append({
                'function': func_name,
                'filename': filename,
                'line': line,
                'calls': nc,
                'total_time': tt,
                'cumulative_time': ct,
                'per_call_time': tt / nc if nc > 0 else 0
            })

        # æŒ‰ç´¯ç©æ™‚é–“æ’åº
        metrics.sort(key=lambda x: x['cumulative_time'], reverse=True)

        return metrics[:20]  # è¿”å›å‰ 20 å€‹

    def _get_memory_stats(self) -> Dict:
        """ç²å–å…§å­˜çµ±è¨ˆ"""
        current, peak = tracemalloc.get_traced_memory()

        # ç²å–å‰ 10 å€‹å…§å­˜åˆ†é…
        snapshot = tracemalloc.take_snapshot()
        top_stats = snapshot.statistics('lineno')

        top_allocations = []
        for stat in top_stats[:10]:
            top_allocations.append({
                'file': stat.traceback.format()[0] if stat.traceback else 'unknown',
                'size_mb': stat.size / 1024 / 1024,
                'count': stat.count
            })

        return {
            'current_mb': current / 1024 / 1024,
            'peak_mb': peak / 1024 / 1024,
            'top_allocations': top_allocations
        }

    def _generate_recommendations(self, stats: List[Dict],
                                  execution_time: float) -> List[Dict]:
        """ç”Ÿæˆæ€§èƒ½å„ªåŒ–å»ºè­°"""
        recommendations = []

        # æª¢æŸ¥æ…¢å‡½æ•¸
        for metric in stats[:5]:  # æª¢æŸ¥å‰ 5 å€‹æœ€æ…¢çš„å‡½æ•¸
            if metric['cumulative_time'] > 1.0:  # è¶…é 1 ç§’
                recommendations.append({
                    'severity': 'high',
                    'category': 'performance',
                    'function': metric['function'],
                    'message': f"å‡½æ•¸ '{metric['function']}' è€—æ™‚ {metric['cumulative_time']:.2f} ç§’",
                    'suggestion': "è€ƒæ…®å„ªåŒ–æ­¤å‡½æ•¸çš„å¯¦ç¾æˆ–ä½¿ç”¨ç·©å­˜"
                })

        # æª¢æŸ¥é »ç¹èª¿ç”¨
        for metric in stats:
            if metric['calls'] > 1000:
                recommendations.append({
                    'severity': 'medium',
                    'category': 'performance',
                    'function': metric['function'],
                    'message': f"å‡½æ•¸ '{metric['function']}' è¢«èª¿ç”¨ {metric['calls']} æ¬¡",
                    'suggestion': "è€ƒæ…®æ¸›å°‘èª¿ç”¨æ¬¡æ•¸æˆ–ä½¿ç”¨ç·©å­˜æ©Ÿåˆ¶"
                })

        # æª¢æŸ¥ç¸½åŸ·è¡Œæ™‚é–“
        if execution_time > 10.0:
            recommendations.append({
                'severity': 'high',
                'category': 'performance',
                'message': f"ç¸½åŸ·è¡Œæ™‚é–“éé•·: {execution_time:.2f} ç§’",
                'suggestion': "è€ƒæ…®ä½¿ç”¨ä¸¦è¡Œè™•ç†æˆ–å„ªåŒ–ç®—æ³•"
            })

        return recommendations

    def generate_report(self, profile_result: Dict, format: str = 'text',
                       output_file: Optional[str] = None):
        """ç”Ÿæˆæ€§èƒ½å ±å‘Š"""
        if format == 'json':
            report = self._generate_json_report(profile_result)
        elif format == 'html':
            report = self._generate_html_report(profile_result)
        else:
            report = self._generate_text_report(profile_result)

        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"\nâœ“ å ±å‘Šå·²å„²å­˜è‡³: {output_file}")
        else:
            print(report)

    def _generate_text_report(self, result: Dict) -> str:
        """ç”Ÿæˆæ–‡å­—å ±å‘Š"""
        lines = [
            "\n" + "="*80,
            "æ€§èƒ½åˆ†æå ±å‘Š",
            "="*80,
            f"\nç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        ]

        # åŸºæœ¬ä¿¡æ¯
        if 'script' in result:
            lines.append(f"\nè…³æœ¬: {result['script']}")
        elif 'function' in result:
            lines.append(f"\nå‡½æ•¸: {result['function']}")

        lines.append(f"åŸ·è¡Œç‹€æ…‹: {'æˆåŠŸ' if result.get('success', True) else 'å¤±æ•—'}")

        if result.get('error'):
            lines.append(f"éŒ¯èª¤: {result['error']}")

        lines.append(f"åŸ·è¡Œæ™‚é–“: {result.get('execution_time', 0):.4f} ç§’")

        # CPU çµ±è¨ˆ
        if 'cpu_stats' in result and result['cpu_stats']:
            lines.append(f"\n{'='*80}")
            lines.append("CPU æ€§èƒ½çµ±è¨ˆ (å‰ 10 å€‹æœ€è€—æ™‚çš„å‡½æ•¸)")
            lines.append("="*80)
            lines.append(f"{'å‡½æ•¸':<40} {'èª¿ç”¨æ¬¡æ•¸':>10} {'ç¸½æ™‚é–“(ç§’)':>15} {'ç´¯ç©æ™‚é–“(ç§’)':>15}")
            lines.append("-"*80)

            for stat in result['cpu_stats'][:10]:
                lines.append(
                    f"{stat['function'][:40]:<40} "
                    f"{stat['calls']:>10} "
                    f"{stat['total_time']:>15.4f} "
                    f"{stat['cumulative_time']:>15.4f}"
                )

        # å…§å­˜çµ±è¨ˆ
        if result.get('memory_stats'):
            mem = result['memory_stats']
            lines.append(f"\n{'='*80}")
            lines.append("å…§å­˜ä½¿ç”¨çµ±è¨ˆ")
            lines.append("="*80)
            lines.append(f"ç•¶å‰å…§å­˜: {mem['current_mb']:.2f} MB")
            lines.append(f"å³°å€¼å…§å­˜: {mem['peak_mb']:.2f} MB")

            if mem.get('top_allocations'):
                lines.append("\nå…§å­˜åˆ†é…å‰ 5 å:")
                for i, alloc in enumerate(mem['top_allocations'][:5], 1):
                    lines.append(f"{i}. {alloc['file']}")
                    lines.append(f"   å¤§å°: {alloc['size_mb']:.2f} MB, æ¬¡æ•¸: {alloc['count']}")

        # æ€§èƒ½å»ºè­°
        if result.get('recommendations'):
            lines.append(f"\n{'='*80}")
            lines.append("æ€§èƒ½å„ªåŒ–å»ºè­°")
            lines.append("="*80)

            for i, rec in enumerate(result['recommendations'], 1):
                severity_icon = {
                    'high': 'ğŸ”´',
                    'medium': 'ğŸŸ¡',
                    'low': 'ğŸ”µ'
                }.get(rec['severity'], 'âšª')

                lines.append(f"\n{i}. {severity_icon} [{rec['category']}]")
                lines.append(f"   {rec['message']}")
                if rec.get('suggestion'):
                    lines.append(f"   ğŸ’¡ å»ºè­°: {rec['suggestion']}")

        # åŸºæº–æ¸¬è©¦çµæœ
        if 'iterations' in result:
            lines.append(f"\n{'='*80}")
            lines.append("åŸºæº–æ¸¬è©¦çµæœ")
            lines.append("="*80)
            lines.append(f"è¿­ä»£æ¬¡æ•¸: {result['iterations']}")
            lines.append(f"å¹³å‡æ™‚é–“: {result['average_time']*1000:.4f} ms")
            lines.append(f"æœ€å°æ™‚é–“: {result['min_time']*1000:.4f} ms")
            lines.append(f"æœ€å¤§æ™‚é–“: {result['max_time']*1000:.4f} ms")
            lines.append(f"æ¨™æº–å·®: {result['std_dev']*1000:.4f} ms")
            lines.append(f"ååé‡: {result['throughput']:.2f} ops/sec")

        lines.append("\n" + "="*80)
        return '\n'.join(lines)

    def _generate_json_report(self, result: Dict) -> str:
        """ç”Ÿæˆ JSON å ±å‘Š"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'profile_result': result
        }
        return json.dumps(report, indent=2, ensure_ascii=False)

    def _generate_html_report(self, result: Dict) -> str:
        """ç”Ÿæˆ HTML å ±å‘Š"""
        execution_time = result.get('execution_time', 0)

        html = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>æ€§èƒ½åˆ†æå ±å‘Š</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; }}
        h1 {{ color: #333; border-bottom: 3px solid #4CAF50; padding-bottom: 10px; }}
        .summary {{ background: #f9f9f9; padding: 20px; border-radius: 5px; margin: 20px 0; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
        th {{ background-color: #4CAF50; color: white; }}
        tr:nth-child(even) {{ background-color: #f9f9f9; }}
        .recommendation {{ margin: 10px 0; padding: 15px; border-left: 4px solid #ddd; background: #fafafa; }}
        .high {{ border-left-color: #f44336; }}
        .medium {{ border-left-color: #ff9800; }}
        .low {{ border-left-color: #2196F3; }}
        .metric {{ display: inline-block; margin: 10px; padding: 15px; background: #e8f5e9; border-radius: 5px; min-width: 150px; text-align: center; }}
        .metric-value {{ font-size: 24px; font-weight: bold; color: #4CAF50; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>âš¡ æ€§èƒ½åˆ†æå ±å‘Š</h1>

        <div class="summary">
            <h2>åŸ·è¡Œæ‘˜è¦</h2>
            <div class="metric">
                <div>åŸ·è¡Œæ™‚é–“</div>
                <div class="metric-value">{execution_time:.4f}s</div>
            </div>
"""

        if result.get('memory_stats'):
            mem = result['memory_stats']
            html += f"""
            <div class="metric">
                <div>å³°å€¼å…§å­˜</div>
                <div class="metric-value">{mem['peak_mb']:.2f} MB</div>
            </div>
"""

        html += "</div>"

        # CPU çµ±è¨ˆè¡¨
        if result.get('cpu_stats'):
            html += """
        <h2>CPU æ€§èƒ½çµ±è¨ˆ</h2>
        <table>
            <tr>
                <th>å‡½æ•¸</th>
                <th>èª¿ç”¨æ¬¡æ•¸</th>
                <th>ç¸½æ™‚é–“ (ç§’)</th>
                <th>ç´¯ç©æ™‚é–“ (ç§’)</th>
                <th>æ¯æ¬¡èª¿ç”¨ (ç§’)</th>
            </tr>
"""
            for stat in result['cpu_stats'][:15]:
                html += f"""
            <tr>
                <td>{stat['function']}</td>
                <td>{stat['calls']}</td>
                <td>{stat['total_time']:.6f}</td>
                <td>{stat['cumulative_time']:.6f}</td>
                <td>{stat['per_call_time']:.6f}</td>
            </tr>
"""
            html += "</table>"

        # å„ªåŒ–å»ºè­°
        if result.get('recommendations'):
            html += "<h2>æ€§èƒ½å„ªåŒ–å»ºè­°</h2>"
            for rec in result['recommendations']:
                severity_class = rec['severity']
                html += f"""
        <div class="recommendation {severity_class}">
            <strong>[{rec['category']}] {rec['message']}</strong>
            <p>ğŸ’¡ å»ºè­°: {rec.get('suggestion', 'N/A')}</p>
        </div>
"""

        html += """
    </div>
</body>
</html>
"""
        return html


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(
        description="æ€§èƒ½åˆ†æå·¥å…· - åˆ†æç¨‹å¼ç¢¼æ€§èƒ½ä¸¦æä¾›å„ªåŒ–å»ºè­°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  %(prog)s script.py                    # åˆ†æè…³æœ¬æ€§èƒ½
  %(prog)s script.py --memory           # å•Ÿç”¨å…§å­˜è¿½è¹¤
  %(prog)s script.py -f html -o report.html  # ç”Ÿæˆ HTML å ±å‘Š
        """
    )

    parser.add_argument('script', nargs='?', help='è¦åˆ†æçš„è…³æœ¬')
    parser.add_argument('--memory', action='store_true',
                       help='å•Ÿç”¨å…§å­˜è¿½è¹¤')
    parser.add_argument('--format', '-f',
                       choices=['text', 'json', 'html'],
                       default='text',
                       help='å ±å‘Šæ ¼å¼')
    parser.add_argument('-o', '--output', help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘')

    args = parser.parse_args()

    profiler = PerformanceProfiler()
    profiler.memory_enabled = args.memory

    try:
        if args.script:
            # åˆ†æè…³æœ¬
            result = profiler.profile_script(args.script)
            profiler.generate_report(result, format=args.format, output_file=args.output)
        else:
            parser.print_help()
            sys.exit(1)

    except Exception as e:
        print(f"\néŒ¯èª¤: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
